# action_financial.py
from toolset.utils.get_financial_statements import get_all_financial_statements, save_financial_statements_to_csv
from toolset.utils.get_stock_intro import get_stock_intro, save_stock_intro_to_txt
from toolset.utils.get_shareholder_info import get_shareholder_info, get_table_content
from toolset.utils.search_engine import SearchEngine
from toolset.utils.identify_competitors import identify_competitors_with_ai
from toolset.utils.markdown_utils import extract_images_from_markdown, save_markdown, format_markdown, convert_to_docx
from toolset.utils.analyzer import Analyzer
from typing import List
from toolset.utils.report_generation_helper import extract_images_from_markdown, load_report_content, get_background, generate_outline, generate_section
from duckduckgo_search import DDGS
import time, random, os
from datetime import datetime
import glob
import json

class FinancialActionToolset:
    def __init__(self, profile, memory, llm, llm_config):
        self.p = profile
        self.m = memory
        self.llm = llm
        self.cfg = llm_config
        # åˆå§‹åŒ–é»˜è®¤æŠ¥å‘Šè·¯å¾„
        self.reports_dir = os.path.join(self.m.data_dir, "reports")
        self.default_report_path = os.path.join(self.reports_dir, "financial_analysis_report.md")
        # Analyzer initialized
        self.analyzer = Analyzer(llm_config=llm_config, llm=llm, output_dir=self.m.data_dir, absolute_path=False)

    #### DATA COLLECTION ACTIONS ####
    def get_competitor_listed_companies(self, context):

        result = identify_competitors_with_ai(
            api_key=self.cfg.api_key,
            base_url=self.cfg.base_url,
            model_name=self.cfg.model,
            company_name=self.p.get_config()['company']
        )
        result = [c for c in result if c.get('market') != "æœªä¸Šå¸‚"]
        return result

    def get_all_financial_data(self, context):
        companies = context.get("all_companies", [])
        data_lst = []
        for p in companies:
            try:
                company, code, market = p['company'], p['code'], p['market']
                print(f"è·å–ï¼š{company}({market}:{code})")
                data = get_all_financial_statements(code, market, "å¹´åº¦")
                data_lst.append(data)
                save_financial_statements_to_csv(data, code, market, "å¹´åº¦", company, self.m.data_dir)
                time.sleep(2)
            except Exception as e:
                print(f"âš ï¸ è·å–å¤±è´¥: {e}")
        return data_lst

    def get_all_company_info(self, context):
        def _parse_market( market_str: str, code: str) -> tuple[str, str]:
            """
            è§£æå¸‚åœºä¿¡æ¯å¹¶æ ¼å¼åŒ–è‚¡ç¥¨ä»£ç 
            
            Args:
                market_str (str): å¸‚åœºæè¿°å­—ç¬¦ä¸²ï¼ˆå¦‚"Aè‚¡"ã€"æ¸¯è‚¡"ç­‰ï¼‰
                code (str): åŸå§‹è‚¡ç¥¨ä»£ç 
                
            Returns:
                Tuple[str, str]: è§£æåçš„å¸‚åœºä»£ç å’Œæ ¼å¼åŒ–çš„è‚¡ç¥¨ä»£ç 
                            - Aè‚¡ï¼šè¿”å›("A", "SH000001"æˆ–"SZ000001"æ ¼å¼)
                            - æ¸¯è‚¡ï¼šè¿”å›("HK", åŸä»£ç )
            """
            if "A" in market_str:
                market = "A"
                if not code.startswith("SH") and not code.startswith("SZ"):
                    code = "SH" + code if code.startswith("6") else "SZ" + code
                return market, code
            elif "æ¸¯" in market_str:
                market = "HK"
                return market, code
            return market_str, code

        companies = context.get("all_companies", [])
        for c in companies:
            if 'market' in c and 'code' in c:
                market, code = _parse_market(c['market'], c['code'])
                c['market'] = market
                c['code'] = code
        context["all_companies"] = companies

        result = ""
        for item in companies:
            info = get_stock_intro(item['code'], item['market'])
            if info:
                result += info
                # ä¿å­˜ç®€ä»‹åˆ°txtæ–‡ä»¶
                company = item.get('company', item['code'])
                filecompany = f"{company}_{item['market']}_{item['code']}.txt"
                save_path = os.path.join(self.m.info_dir, filecompany)
                save_stock_intro_to_txt(item['code'], item['market'], save_path)
        return result

    def get_shareholder_analysis(self, context):
        info = get_shareholder_info()
        if info['success']:
            content = get_table_content(info['tables'])
            return self.llm.call("åˆ†æä»¥ä¸‹è‚¡ä¸œä¿¡æ¯ï¼š\n" + content, system_prompt="ä½ æ˜¯è‚¡ä¸œåˆ†æä¸“å®¶")
        return "è‚¡ä¸œä¿¡æ¯è·å–å¤±è´¥"

    def search_industry_info(self, context, engine: str = "sogou"):
        # å¦‚æœdata/industry_info/all_search_results.jsonå­˜åœ¨ï¼Œåˆ™è¯»å–
        search_results_path = os.path.join(self.m.industry_dir, "all_search_results.json")
        if os.path.exists(search_results_path):
            with open(search_results_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        
        # å¦åˆ™è¿›è¡Œæœç´¢
        companies = [self.p.get_config()['company']] + [c['company'] for c in context.get("all_companies", [])]
        results = {}
        for company in companies:
            r = SearchEngine(engine).search(f"{company} å¸‚åœºä»½é¢ è¡Œä¸šåˆ†æ", max_results=10)
            results[company] = r
            # æ‹¼æ¥æ‰€æœ‰æè¿°
            # all_desc = "\n".join([item['description'] for item in r if 'description' in item])
            # # ç”¨LLMç”Ÿæˆæ‘˜è¦
            # summary = self.llm.call(f"è¯·ç”¨ä¸­æ–‡ç®€è¦æ€»ç»“ä»¥ä¸‹å…³äº{company}çš„è¡Œä¸šå¸‚åœºä»½é¢å’Œç«äº‰åœ°ä½ä¿¡æ¯ï¼š\n{all_desc}", system_prompt="ä½ æ˜¯è¡Œä¸šåˆ†æä¸“å®¶")
            # results[company] = {
            #     "search_results": r,
            #     "summary": summary
            # }
            time.sleep(random.randint(5, 10))

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(self.m.industry_dir, exist_ok=True)
        with open(search_results_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        return results

    #### DATA ANALYSIS ACTIONS ####
    def quick_analysis(self, query, files=None):
        """
        å¿«é€Ÿæ•°æ®åˆ†æå‡½æ•°
        
        Args:
            query: åˆ†æéœ€æ±‚ï¼ˆè‡ªç„¶è¯­è¨€ï¼‰
            files: æ•°æ®æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            output_dir: è¾“å‡ºç›®å½•
            max_rounds: æœ€å¤§åˆ†æè½®æ•°
            
        Returns:
            dict: åˆ†æç»“æœ
        """
        return self.analyzer.analyze(query, files or [])
    
    def get_company_files(self, data_dir):
        """è·å–å…¬å¸æ–‡ä»¶"""
        abs_data_dir = os.path.abspath(data_dir)
        print(f"è·å–å…¬å¸æ•°æ®ç›®å½•: {abs_data_dir}")
        all_files = glob.glob(f"{abs_data_dir}/*.csv")
        companies = {}
        for file in all_files:
            filename = os.path.basename(file)
            company_name = filename.split("_")[0]
            companies.setdefault(company_name, []).append(file)
        return companies

    def analyze_companies_in_directory(self, context):
        """
        åˆ†ææŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰å…¬å¸æ•°æ®
        """
        def analyze_companies(data_directory, query="åŸºäºè¡¨æ ¼çš„æ•°æ®ï¼Œåˆ†ææœ‰ä»·å€¼çš„å†…å®¹ï¼Œå¹¶ç»˜åˆ¶ç›¸å…³å›¾è¡¨ã€‚æœ€åç”Ÿæˆæ±‡æŠ¥ç»™æˆ‘ã€‚"):
            """åˆ†æç›®å½•ä¸­çš„æ‰€æœ‰å…¬å¸"""
            def analyze_individual_company(files, query=None):
                """åˆ†æå•ä¸ªå…¬å¸"""
                if query is None:
                    query = "åŸºäºè¡¨æ ¼çš„æ•°æ®ï¼Œåˆ†ææœ‰ä»·å€¼çš„å†…å®¹ï¼Œå¹¶ç»˜åˆ¶ç›¸å…³å›¾è¡¨ã€‚æœ€åç”Ÿæˆæ±‡æŠ¥ç»™æˆ‘ã€‚"
                report = self.quick_analysis(
                    query=query, files=files
                )
                return report

            company_files = self.get_company_files(data_directory)
            all_reports = {}
            for company_name, files in company_files.items():
                report = analyze_individual_company(files, query)
                if report:
                    all_reports[company_name] = report
            return all_reports

        results = analyze_companies(
            data_directory=self.m.data_dir,
            query="åŸºäºè¡¨æ ¼çš„æ•°æ®ï¼Œåˆ†ææœ‰ä»·å€¼çš„å†…å®¹ï¼Œå¹¶ç»˜åˆ¶ç›¸å…³å›¾è¡¨ã€‚æœ€åç”Ÿæˆæ±‡æŠ¥ç»™æˆ‘ã€‚"
        )

        return results

    def run_comparison_analysis(self, context):
        """
        è¿è¡Œç«äº‰å¯¹æ‰‹åˆ†æ
        """
        def comparison_analysis(data_directory, target_company_name):
            """è¿è¡Œå¯¹æ¯”åˆ†æ"""
            company_files = self.get_company_files(data_directory)
            if not company_files or target_company_name not in company_files:
                return {}
            competitors = [company for company in company_files.keys() if company != target_company_name]
            comparison_reports = {}
            for competitor in competitors:
                comparison_key = f"{target_company_name}_vs_{competitor}"
                report = compare_two_companies(
                    company_files[target_company_name],
                    company_files[competitor]
                )
                if report:
                    comparison_reports[comparison_key] = {
                        'company1': target_company_name,
                        'company2': competitor,
                        'report': report
                    }
            return comparison_reports

        def compare_two_companies(company1_files, company2_files):
            """æ¯”è¾ƒä¸¤ä¸ªå…¬å¸"""
            query = "åŸºäºä¸¤ä¸ªå…¬å¸çš„è¡¨æ ¼çš„æ•°æ®ï¼Œåˆ†ææœ‰å…±åŒç‚¹çš„éƒ¨åˆ†ï¼Œç»˜åˆ¶å¯¹æ¯”åˆ†æçš„è¡¨æ ¼ï¼Œå¹¶ç»˜åˆ¶ç›¸å…³å›¾è¡¨ã€‚æœ€åç”Ÿæˆæ±‡æŠ¥ç»™æˆ‘ã€‚"
            all_files = company1_files + company2_files
            report = self.quick_analysis(
                query=query,
                files=all_files,
            )
            return report
        
        comparison_results = comparison_analysis(
            data_directory=self.m.data_dir,
            target_company_name=self.p.get_config()['company']
        )

        return comparison_results
    
    def merge_reports(self, context):
        """åˆå¹¶æŠ¥å‘Š"""
        individual_reports = context.get("individual_reports", {})
        comparison_reports = context.get("comparison_reports", {})
        merged = {}
        for company, report in individual_reports.items():
            merged[company] = report
        for comp_key, comp_data in comparison_reports.items():
            merged[comp_key] = comp_data['report']
        return merged
    
    def evaluation(self, context):
        def get_sensetime_files(data_dir):
            """è·å–å•†æ±¤ç§‘æŠ€çš„è´¢åŠ¡æ•°æ®æ–‡ä»¶"""
            abs_data_dir = os.path.abspath(data_dir)
            print(f"è·å–å•†æ±¤ç§‘æŠ€è´¢åŠ¡æ•°æ®ç›®å½•: {abs_data_dir}")
            all_files = glob.glob(f"{abs_data_dir}/*.csv")
            sensetime_files = []
            for file in all_files:
                filename = os.path.basename(file)
                company_name = filename.split("_")[0]
                if "å•†æ±¤" in company_name or "SenseTime" in company_name:
                    sensetime_files.append(file)
            return sensetime_files
        def analyze_sensetime_valuation(files):
            """åˆ†æå•†æ±¤ç§‘æŠ€çš„ä¼°å€¼ä¸é¢„æµ‹"""
            query = "åŸºäºä¸‰å¤§è¡¨çš„æ•°æ®ï¼Œæ„å»ºä¼°å€¼ä¸é¢„æµ‹æ¨¡å‹ï¼Œæ¨¡æ‹Ÿå…³é”®å˜é‡å˜åŒ–å¯¹è´¢åŠ¡ç»“æœçš„å½±å“,å¹¶ç»˜åˆ¶ç›¸å…³å›¾è¡¨ã€‚æœ€åç”Ÿæˆæ±‡æŠ¥ç»™æˆ‘ã€‚"
            report = self.quick_analysis(query=query, files=files)
            return report

        # å•†æ±¤ç§‘æŠ€ä¼°å€¼ä¸é¢„æµ‹åˆ†æ
        sensetime_files = get_sensetime_files(self.m.data_dir)
        sensetime_valuation_report = None
        if sensetime_files:
            sensetime_valuation_report = analyze_sensetime_valuation(sensetime_files)
        return sensetime_valuation_report if sensetime_valuation_report else "å•†æ±¤ç§‘æŠ€çš„ä¼°å€¼ä¸é¢„æµ‹åˆ†ææœªèƒ½å®Œæˆæˆ–æ— ç›¸å…³æ•°æ®ã€‚"
    
    def get_analysis_report(self, context):
        """
        è·å–åˆ†ææŠ¥å‘Š
        """
        def get_company_infos(data_dir="./data/info"):
            """è·å–å…¬å¸ä¿¡æ¯"""
            abs_data_dir = os.path.abspath(data_dir)
            print(f"è·å–å…¬å¸ä¿¡æ¯ç›®å½•: {abs_data_dir}")
            all_files = os.listdir(abs_data_dir)
            company_infos = ""
            for file in all_files:
                if file.endswith(".txt"):
                    company_name = file.split(".")[0]
                    with open(os.path.join(data_dir, file), 'r', encoding='utf-8') as f:
                        content = f.read()
                    company_infos += f"ã€å…¬å¸ä¿¡æ¯å¼€å§‹ã€‘\nå…¬å¸åç§°: {company_name}\n{content}\nã€å…¬å¸ä¿¡æ¯ç»“æŸã€‘\n\n"
            return company_infos
        
        def format_final_reports(all_reports):
            """æ ¼å¼åŒ–æœ€ç»ˆæŠ¥å‘Š"""
            formatted_output = []
            for company_name, report in all_reports.items():
                formatted_output.append(f"ã€{company_name}è´¢åŠ¡æ•°æ®åˆ†æç»“æœå¼€å§‹ã€‘")
                final_report = report.get("final_report", "æœªç”ŸæˆæŠ¥å‘Š")
                formatted_output.append(final_report)
                formatted_output.append(f"ã€{company_name}è´¢åŠ¡æ•°æ®åˆ†æç»“æœç»“æŸã€‘")
                formatted_output.append("")
            return "\n".join(formatted_output)
        
        # æ•´ç†å…¬å¸ä¿¡æ¯
        company_infos = get_company_infos()
        company_infos = self.llm.call(
            f"è¯·æ•´ç†ä»¥ä¸‹å…¬å¸ä¿¡æ¯å†…å®¹ï¼Œç¡®ä¿æ ¼å¼æ¸…æ™°æ˜“è¯»ï¼Œå¹¶ä¿ç•™å…³é”®ä¿¡æ¯ï¼š\n{company_infos}",
            system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å…¬å¸ä¿¡æ¯æ•´ç†å¸ˆã€‚",
            max_tokens=8192,
            temperature=0.5
        )
        
        # æ•´ç†è‚¡æƒä¿¡æ¯
        info = get_shareholder_info()
        shangtang_shareholder_info = info.get("tables", [])
        table_content = get_table_content(shangtang_shareholder_info)
        shareholder_analysis = self.llm.call(
            "è¯·åˆ†æä»¥ä¸‹è‚¡ä¸œä¿¡æ¯è¡¨æ ¼å†…å®¹ï¼š\n" + table_content,
            system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è‚¡ä¸œä¿¡æ¯åˆ†æå¸ˆã€‚",
            max_tokens=8192,
            temperature=0.5
        )
        
        # æ•´ç†è¡Œä¸šä¿¡æ¯æœç´¢ç»“æœ
        search_results_file = os.path.join(self.m.industry_dir, "all_search_results.json")
        with open(search_results_file, 'r', encoding='utf-8') as f:
            all_search_results = json.load(f)
        search_res = ""
        for company, results in all_search_results.items():
            search_res += f"ã€{company}æœç´¢ä¿¡æ¯å¼€å§‹ã€‘\n"
            for result in results:
                search_res += f"æ ‡é¢˜: {result.get('title', 'æ— æ ‡é¢˜')}\n"
                search_res += f"é“¾æ¥: {result.get('href', 'æ— é“¾æ¥')}\n"
                search_res += f"æ‘˜è¦: {result.get('body', 'æ— æ‘˜è¦')}\n"
                search_res += "----\n"
            search_res += f"ã€{company}æœç´¢ä¿¡æ¯ç»“æŸã€‘\n\n"
        
        # ä¿å­˜é˜¶æ®µä¸€ç»“æœ
        merged_results = context.get("merged_results", {})
        sensetime_valuation_report = context.get("sensetime_valuation_report", None)
        formatted_report = format_final_reports(merged_results)
        
        # ç»Ÿä¸€ä¿å­˜ä¸ºmarkdown
        md_output_file = f"è´¢åŠ¡ç ”æŠ¥æ±‡æ€»_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        with open(md_output_file, 'w', encoding='utf-8') as f:
            f.write(f"# å…¬å¸åŸºç¡€ä¿¡æ¯\n\n## æ•´ç†åå…¬å¸ä¿¡æ¯\n\n{company_infos}\n\n")
            f.write(f"# è‚¡æƒä¿¡æ¯åˆ†æ\n\n{shareholder_analysis}\n\n")
            f.write(f"# è¡Œä¸šä¿¡æ¯æœç´¢ç»“æœ\n\n{search_res}\n\n")
            f.write(f"# è´¢åŠ¡æ•°æ®åˆ†æä¸ä¸¤ä¸¤å¯¹æ¯”\n\n{formatted_report}\n\n")
            if sensetime_valuation_report and isinstance(sensetime_valuation_report, dict):
                f.write(f"# å•†æ±¤ç§‘æŠ€ä¼°å€¼ä¸é¢„æµ‹åˆ†æ\n\n{sensetime_valuation_report.get('final_report', 'æœªç”ŸæˆæŠ¥å‘Š')}\n\n")
        
        print(f"\nâœ… ç¬¬ä¸€é˜¶æ®µå®Œæˆï¼åŸºç¡€åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {md_output_file}")
        
        # å­˜å‚¨ç»“æœä¾›ç¬¬äºŒé˜¶æ®µä½¿ç”¨
        self.analysis_results = {
            'md_file': md_output_file,
            'company_infos': company_infos,
            'shareholder_analysis': shareholder_analysis,
            'search_res': search_res,
            'formatted_report': formatted_report,
            'sensetime_valuation_report': sensetime_valuation_report
        }
        return md_output_file
    


    #### REPORT GENERATION ACTIONS ####
    def deep_report_generation(self, context):
        """ç¬¬äºŒé˜¶æ®µï¼šæ·±åº¦ç ”æŠ¥ç”Ÿæˆ"""
        print("\n" + "="*80)
        print("ğŸš€ å¼€å§‹ç¬¬äºŒé˜¶æ®µï¼šæ·±åº¦ç ”æŠ¥ç”Ÿæˆ")
        print("="*80)
        
        # å¤„ç†å›¾ç‰‡è·¯å¾„
        print("ğŸ–¼ï¸ å¤„ç†å›¾ç‰‡è·¯å¾„...")
        md_file_path = context.get("get_analysis_report", self.default_report_path)
        new_md_path = md_file_path.replace('.md', '_images.md')
        images_dir = os.path.join(os.path.dirname(md_file_path), 'images')
        extract_images_from_markdown(md_file_path, images_dir, new_md_path)
        
        # åŠ è½½æŠ¥å‘Šå†…å®¹
        report_content = load_report_content(new_md_path)
        background = get_background()
        
        # ç”Ÿæˆå¤§çº²
        print("\nğŸ“‹ ç”ŸæˆæŠ¥å‘Šå¤§çº²...")
        parts = generate_outline(self.llm, background, report_content)
        
        # åˆ†æ®µç”Ÿæˆæ·±åº¦ç ”æŠ¥
        print("\nâœï¸ å¼€å§‹åˆ†æ®µç”Ÿæˆæ·±åº¦ç ”æŠ¥...")
        full_report = ['# å•†æ±¤ç§‘æŠ€å…¬å¸ç ”æŠ¥\n']
        prev_content = ''
        
        for idx, part in enumerate(parts):
            part_title = part.get('part_title', f'éƒ¨åˆ†{idx+1}')
            print(f"\n  æ­£åœ¨ç”Ÿæˆï¼š{part_title}")
            is_last = (idx == len(parts) - 1)
            section_text = generate_section(
                self.llm, part_title, prev_content, background, report_content, is_last
            )
            full_report.append(section_text)
            print(f"  âœ… å·²å®Œæˆï¼š{part_title}")
            prev_content = '\n'.join(full_report)
        
        # ä¿å­˜æœ€ç»ˆæŠ¥å‘Š
        final_report = '\n\n'.join(full_report)
        output_file = f"æ·±åº¦è´¢åŠ¡ç ”æŠ¥åˆ†æ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        save_markdown(final_report, output_file)
        
        # æ ¼å¼åŒ–å’Œè½¬æ¢
        print("\nğŸ¨ æ ¼å¼åŒ–æŠ¥å‘Š...")
        format_markdown(output_file)
        
        print("\nğŸ“„ è½¬æ¢ä¸ºWordæ–‡æ¡£...")
        convert_to_docx(output_file)
        
        print(f"\nâœ… ç¬¬äºŒé˜¶æ®µå®Œæˆï¼æ·±åº¦ç ”æŠ¥å·²ä¿å­˜åˆ°: {output_file}")
        return output_file