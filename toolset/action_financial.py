# action_financial.py
from toolset.utils.get_financial_statements import get_all_financial_statements, save_financial_statements_to_csv
from toolset.utils.get_stock_intro import get_stock_intro, save_stock_intro_to_txt
from toolset.utils.get_shareholder_info import get_shareholder_info, get_table_content
from toolset.utils.search_engine import SearchEngine
from toolset.utils.identify_competitors import identify_competitors_with_ai
from toolset.utils.markdown_utils import save_markdown, format_markdown, convert_to_docx, extract_images_from_markdown, load_report_content, get_background, generate_outline, generate_section
from toolset.utils.analyzer import Analyzer
from toolset.utils.industry_data_collector import IndustryDataCollector
from toolset.utils.macro_data_collector import MacroDataCollector
from toolset.utils.report_type_config import ReportTypeConfig, ReportType
import time, random, os
from datetime import datetime
import glob
import json

class FinancialActionToolset:
    def __init__(self, profile, memory, llm, llm_config):
        self.p = profile
        self.m = memory
        self.llm = llm
        self.cfg = llm_config
        # åˆå§‹åŒ–é»˜è®¤æŠ¥å‘Šè·¯å¾„
        self.reports_dir = os.path.join(self.m.data_dir, "reports")
        self.default_report_path = os.path.join(self.reports_dir, "financial_analysis_report.md")
        # Analyzer initialized
        self.analyzer = Analyzer(llm_config=llm_config, llm=llm, output_dir=self.m.data_dir, absolute_path=False)
        
        # åˆå§‹åŒ–æ–°çš„æ•°æ®æ”¶é›†å™¨
        self.industry_collector = IndustryDataCollector()
        self.macro_collector = MacroDataCollector()
        self.report_config = ReportTypeConfig()
        
        # å½“å‰ç ”æŠ¥ç±»å‹ï¼ˆä»profileé…ç½®ä¸­è·å–ï¼Œé»˜è®¤ä¸ºå…¬å¸ç ”æŠ¥ï¼‰
        self.current_report_type = self._determine_report_type()
    
    def _determine_report_type(self) -> ReportType:
        """ç¡®å®šç ”æŠ¥ç±»å‹"""
        # ä»profileé…ç½®ä¸­è·å–ç ”æŠ¥ç±»å‹
        report_type_str = self.p.get_config().get("report_type", "company")
        
        # ä»æŒ‡ä»¤ä¸­è¯†åˆ«ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        instruction = self.p.get_config().get("instruction", "")
        if instruction:
            return self.report_config.identify_report_type(instruction)
        
        # æ ¹æ®å­—ç¬¦ä¸²æ˜ å°„åˆ°æšä¸¾
        type_mapping = {
            "company": ReportType.COMPANY,
            "industry": ReportType.INDUSTRY, 
            "macro": ReportType.MACRO
        }
        return type_mapping.get(report_type_str.lower(), ReportType.COMPANY)

    #### DATA COLLECTION ACTIONS ####
    def get_competitor_listed_companies(self, context):
        # åªæœ‰å…¬å¸ç ”æŠ¥æ‰éœ€è¦ç«äº‰å¯¹æ‰‹
        if self.current_report_type != ReportType.COMPANY:
            return []
        
        result = identify_competitors_with_ai(
            api_key=self.cfg.api_key,
            base_url=self.cfg.base_url,
            model_name=self.cfg.model,
            company_name=self.p.get_config()['company']
        )
        result = [c for c in result if c.get('market') != "æœªä¸Šå¸‚"]
        return result

    def get_all_financial_data(self, context):
        # åªæœ‰å…¬å¸ç ”æŠ¥æ‰éœ€è¦è´¢åŠ¡æ•°æ®
        if self.current_report_type != ReportType.COMPANY:
            return []
        
        companies = context.get("all_companies", [])
        data_lst = []
        for p in companies:
            try:
                company, code, market = p['company'], p['code'], p['market']
                print(f"è·å–ï¼š{company}({market}:{code})")
                data = get_all_financial_statements(code, market, "å¹´åº¦")
                data_lst.append(data)
                save_financial_statements_to_csv(data, code, market, "å¹´åº¦", company, self.m.data_dir)
                time.sleep(2)
            except Exception as e:
                print(f"âš ï¸ è·å–å¤±è´¥: {e}")
        return data_lst

    def get_all_company_info(self, context):
        # åªæœ‰å…¬å¸ç ”æŠ¥æ‰éœ€è¦å…¬å¸ä¿¡æ¯
        if self.current_report_type != ReportType.COMPANY:
            return ""
        
        def _parse_market( market_str: str, code: str) -> tuple[str, str]:
            """
            è§£æå¸‚åœºä¿¡æ¯å¹¶æ ¼å¼åŒ–è‚¡ç¥¨ä»£ç 
            
            Args:
                market_str (str): å¸‚åœºæè¿°å­—ç¬¦ä¸²ï¼ˆå¦‚"Aè‚¡"ã€"æ¸¯è‚¡"ç­‰ï¼‰
                code (str): åŸå§‹è‚¡ç¥¨ä»£ç 
                
            Returns:
                Tuple[str, str]: è§£æåçš„å¸‚åœºä»£ç å’Œæ ¼å¼åŒ–çš„è‚¡ç¥¨ä»£ç 
                            - Aè‚¡ï¼šè¿”å›("A", "SH000001"æˆ–"SZ000001"æ ¼å¼)
                            - æ¸¯è‚¡ï¼šè¿”å›("HK", åŸä»£ç )
            """
            if "A" in market_str:
                market = "A"
                if not code.startswith("SH") and not code.startswith("SZ"):
                    code = "SH" + code if code.startswith("6") else "SZ" + code
                return market, code
            elif "æ¸¯" in market_str:
                market = "HK"
                return market, code
            return market_str, code

        companies = context.get("all_companies", [])
        for c in companies:
            if 'market' in c and 'code' in c:
                market, code = _parse_market(c['market'], c['code'])
                c['market'] = market
                c['code'] = code
        context["all_companies"] = companies

        result = ""
        for item in companies:
            info = get_stock_intro(item['code'], item['market'])
            if info:
                result += info
                # ä¿å­˜ç®€ä»‹åˆ°txtæ–‡ä»¶
                company = item.get('company', item['code'])
                filecompany = f"{company}_{item['market']}_{item['code']}.txt"
                save_path = os.path.join(self.m.info_dir, filecompany)
                save_stock_intro_to_txt(item['code'], item['market'], save_path)
        return result

    def get_shareholder_analysis(self, context):
        info = get_shareholder_info()
        if info['success']:
            content = get_table_content(info['tables'])
            return self.llm.call("åˆ†æä»¥ä¸‹è‚¡ä¸œä¿¡æ¯ï¼š\n" + content, system_prompt="ä½ æ˜¯è‚¡ä¸œåˆ†æä¸“å®¶")
        return "è‚¡ä¸œä¿¡æ¯è·å–å¤±è´¥"

    def search_industry_info(self, context, engine: str = "sogou"):
        # åªæœ‰å…¬å¸ç ”æŠ¥æ‰éœ€è¦è¡Œä¸šæœç´¢
        if self.current_report_type != ReportType.COMPANY:
            return {}
        
        # å¦‚æœdata/industry_info/all_search_results.jsonå­˜åœ¨ï¼Œåˆ™è¯»å–
        search_results_path = os.path.join(self.m.industry_dir, "all_search_results.json")
        if os.path.exists(search_results_path):
            with open(search_results_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        
        # å¦åˆ™è¿›è¡Œæœç´¢
        companies = [self.p.get_config()['company']] + [c['company'] for c in context.get("all_companies", [])]
        results = {}
        for company in companies:
            r = SearchEngine(engine).search(f"{company} å¸‚åœºä»½é¢ è¡Œä¸šåˆ†æ", max_results=10)
            results[company] = r
            # æ‹¼æ¥æ‰€æœ‰æè¿°
            # all_desc = "\n".join([item['description'] for item in r if 'description' in item])
            # # ç”¨LLMç”Ÿæˆæ‘˜è¦
            # summary = self.llm.call(f"è¯·ç”¨ä¸­æ–‡ç®€è¦æ€»ç»“ä»¥ä¸‹å…³äº{company}çš„è¡Œä¸šå¸‚åœºä»½é¢å’Œç«äº‰åœ°ä½ä¿¡æ¯ï¼š\n{all_desc}", system_prompt="ä½ æ˜¯è¡Œä¸šåˆ†æä¸“å®¶")
            # results[company] = {
            #     "search_results": r,
            #     "summary": summary
            # }
            time.sleep(random.randint(5, 10))

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(self.m.industry_dir, exist_ok=True)
        with open(search_results_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        return results

    #### DATA ANALYSIS ACTIONS ####
    def quick_analysis(self, query, files=None):
        """
        å¿«é€Ÿæ•°æ®åˆ†æå‡½æ•°
        
        Args:
            query: åˆ†æéœ€æ±‚ï¼ˆè‡ªç„¶è¯­è¨€ï¼‰
            files: æ•°æ®æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            output_dir: è¾“å‡ºç›®å½•
            max_rounds: æœ€å¤§åˆ†æè½®æ•°
            
        Returns:
            dict: åˆ†æç»“æœ
        """
        return self.analyzer.analyze(query, files or [])
    
    def get_company_files(self, data_dir):
        """è·å–å…¬å¸æ–‡ä»¶"""
        abs_data_dir = os.path.abspath(data_dir)
        print(f"è·å–å…¬å¸æ•°æ®ç›®å½•: {abs_data_dir}")
        all_files = glob.glob(f"{abs_data_dir}/*.csv")
        companies = {}
        for file in all_files:
            filename = os.path.basename(file)
            company_name = filename.split("_")[0]
            companies.setdefault(company_name, []).append(file)
        return companies

    def analyze_companies_in_directory(self, context):
        """
        åˆ†ææŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰å…¬å¸æ•°æ®
        """
        def analyze_companies(data_directory, query="åŸºäºè¡¨æ ¼çš„æ•°æ®ï¼Œåˆ†ææœ‰ä»·å€¼çš„å†…å®¹ï¼Œå¹¶ç»˜åˆ¶ç›¸å…³å›¾è¡¨ã€‚æœ€åç”Ÿæˆæ±‡æŠ¥ç»™æˆ‘ã€‚"):
            """åˆ†æç›®å½•ä¸­çš„æ‰€æœ‰å…¬å¸"""
            def analyze_individual_company(files, query=None):
                """åˆ†æå•ä¸ªå…¬å¸"""
                if query is None:
                    query = "åŸºäºè¡¨æ ¼çš„æ•°æ®ï¼Œåˆ†ææœ‰ä»·å€¼çš„å†…å®¹ï¼Œå¹¶ç»˜åˆ¶ç›¸å…³å›¾è¡¨ã€‚æœ€åç”Ÿæˆæ±‡æŠ¥ç»™æˆ‘ã€‚"
                report = self.quick_analysis(
                    query=query, files=files
                )
                return report

            company_files = self.get_company_files(data_directory)
            all_reports = {}
            for company_name, files in company_files.items():
                report = analyze_individual_company(files, query)
                if report:
                    all_reports[company_name] = report
            return all_reports

        results = analyze_companies(
            data_directory=self.m.data_dir,
            query="åŸºäºè¡¨æ ¼çš„æ•°æ®ï¼Œåˆ†ææœ‰ä»·å€¼çš„å†…å®¹ï¼Œå¹¶ç»˜åˆ¶ç›¸å…³å›¾è¡¨ã€‚æœ€åç”Ÿæˆæ±‡æŠ¥ç»™æˆ‘ã€‚"
        )

        return results

    def run_comparison_analysis(self, context):
        """
        è¿è¡Œç«äº‰å¯¹æ‰‹åˆ†æ
        """
        # åªæœ‰å…¬å¸ç ”æŠ¥æ‰éœ€è¦å…¬å¸æ¯”è¾ƒ
        if self.current_report_type != ReportType.COMPANY:
            return "éå…¬å¸ç ”æŠ¥ç±»å‹ï¼Œè·³è¿‡å¯¹æ¯”åˆ†æ"
        
        def comparison_analysis(data_directory, target_company_name):
            """è¿è¡Œå¯¹æ¯”åˆ†æ"""
            company_files = self.get_company_files(data_directory)
            if not company_files or target_company_name not in company_files:
                return {}
            competitors = [company for company in company_files.keys() if company != target_company_name]
            comparison_reports = {}
            for competitor in competitors:
                comparison_key = f"{target_company_name}_vs_{competitor}"
                report = compare_two_companies(
                    company_files[target_company_name],
                    company_files[competitor]
                )
                if report:
                    comparison_reports[comparison_key] = {
                        'company1': target_company_name,
                        'company2': competitor,
                        'report': report
                    }
            return comparison_reports

        def compare_two_companies(company1_files, company2_files):
            """æ¯”è¾ƒä¸¤ä¸ªå…¬å¸"""
            query = "åŸºäºä¸¤ä¸ªå…¬å¸çš„è¡¨æ ¼çš„æ•°æ®ï¼Œåˆ†ææœ‰å…±åŒç‚¹çš„éƒ¨åˆ†ï¼Œç»˜åˆ¶å¯¹æ¯”åˆ†æçš„è¡¨æ ¼ï¼Œå¹¶ç»˜åˆ¶ç›¸å…³å›¾è¡¨ã€‚æœ€åç”Ÿæˆæ±‡æŠ¥ç»™æˆ‘ã€‚"
            all_files = company1_files + company2_files
            report = self.quick_analysis(
                query=query,
                files=all_files,
            )
            return report
        
        comparison_results = comparison_analysis(
            data_directory=self.m.data_dir,
            target_company_name=self.p.get_config()['company']
        )

        return comparison_results
    
    def merge_reports(self, context):
        """åˆå¹¶æŠ¥å‘Š"""
        individual_reports = context.get("individual_reports", {})
        comparison_reports = context.get("comparison_reports", {})
        merged = {}
        for company, report in individual_reports.items():
            merged[company] = report
        for comp_key, comp_data in comparison_reports.items():
            merged[comp_key] = comp_data['report']
        return merged
    
    def evaluation(self, context):
        def get_sensetime_files(data_dir):
            """è·å–å•†æ±¤ç§‘æŠ€çš„è´¢åŠ¡æ•°æ®æ–‡ä»¶"""
            abs_data_dir = os.path.abspath(data_dir)
            print(f"è·å–å•†æ±¤ç§‘æŠ€è´¢åŠ¡æ•°æ®ç›®å½•: {abs_data_dir}")
            all_files = glob.glob(f"{abs_data_dir}/*.csv")
            sensetime_files = []
            for file in all_files:
                filename = os.path.basename(file)
                company_name = filename.split("_")[0]
                if "å•†æ±¤" in company_name or "SenseTime" in company_name:
                    sensetime_files.append(file)
            return sensetime_files
        def analyze_sensetime_valuation(files):
            """åˆ†æå•†æ±¤ç§‘æŠ€çš„ä¼°å€¼ä¸é¢„æµ‹"""
            query = "åŸºäºä¸‰å¤§è¡¨çš„æ•°æ®ï¼Œæ„å»ºä¼°å€¼ä¸é¢„æµ‹æ¨¡å‹ï¼Œæ¨¡æ‹Ÿå…³é”®å˜é‡å˜åŒ–å¯¹è´¢åŠ¡ç»“æœçš„å½±å“,å¹¶ç»˜åˆ¶ç›¸å…³å›¾è¡¨ã€‚æœ€åç”Ÿæˆæ±‡æŠ¥ç»™æˆ‘ã€‚"
            report = self.quick_analysis(query=query, files=files)
            return report

        # å•†æ±¤ç§‘æŠ€ä¼°å€¼ä¸é¢„æµ‹åˆ†æ
        sensetime_files = get_sensetime_files(self.m.data_dir)
        sensetime_valuation_report = None
        if sensetime_files:
            sensetime_valuation_report = analyze_sensetime_valuation(sensetime_files)
        return sensetime_valuation_report if sensetime_valuation_report else "å•†æ±¤ç§‘æŠ€çš„ä¼°å€¼ä¸é¢„æµ‹åˆ†ææœªèƒ½å®Œæˆæˆ–æ— ç›¸å…³æ•°æ®ã€‚"
    
    def get_analysis_report(self, context):
        """
        è·å–åˆ†ææŠ¥å‘Š
        """
        def get_company_infos(data_dir="./data/info"):
            """è·å–å…¬å¸ä¿¡æ¯"""
            abs_data_dir = os.path.abspath(data_dir)
            print(f"è·å–å…¬å¸ä¿¡æ¯ç›®å½•: {abs_data_dir}")
            all_files = os.listdir(abs_data_dir)
            company_infos = ""
            for file in all_files:
                if file.endswith(".txt"):
                    company_name = file.split(".")[0]
                    with open(os.path.join(data_dir, file), 'r', encoding='utf-8') as f:
                        content = f.read()
                    company_infos += f"ã€å…¬å¸ä¿¡æ¯å¼€å§‹ã€‘\nå…¬å¸åç§°: {company_name}\n{content}\nã€å…¬å¸ä¿¡æ¯ç»“æŸã€‘\n\n"
            return company_infos
        
        def format_final_reports(all_reports):
            """æ ¼å¼åŒ–æœ€ç»ˆæŠ¥å‘Š"""
            formatted_output = []
            for company_name, report in all_reports.items():
                formatted_output.append(f"ã€{company_name}è´¢åŠ¡æ•°æ®åˆ†æç»“æœå¼€å§‹ã€‘")
                final_report = report.get("final_report", "æœªç”ŸæˆæŠ¥å‘Š")
                formatted_output.append(final_report)
                formatted_output.append(f"ã€{company_name}è´¢åŠ¡æ•°æ®åˆ†æç»“æœç»“æŸã€‘")
                formatted_output.append("")
            return "\n".join(formatted_output)
        
        # æ•´ç†å…¬å¸ä¿¡æ¯
        company_infos = get_company_infos()
        company_infos = self.llm.call(
            f"è¯·æ•´ç†ä»¥ä¸‹å…¬å¸ä¿¡æ¯å†…å®¹ï¼Œç¡®ä¿æ ¼å¼æ¸…æ™°æ˜“è¯»ï¼Œå¹¶ä¿ç•™å…³é”®ä¿¡æ¯ï¼š\n{company_infos}",
            system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å…¬å¸ä¿¡æ¯æ•´ç†å¸ˆã€‚",
            max_tokens=8192,
            temperature=0.5
        )
        
        # æ•´ç†è‚¡æƒä¿¡æ¯
        info = get_shareholder_info()
        shangtang_shareholder_info = info.get("tables", [])
        table_content = get_table_content(shangtang_shareholder_info)
        shareholder_analysis = self.llm.call(
            "è¯·åˆ†æä»¥ä¸‹è‚¡ä¸œä¿¡æ¯è¡¨æ ¼å†…å®¹ï¼š\n" + table_content,
            system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è‚¡ä¸œä¿¡æ¯åˆ†æå¸ˆã€‚",
            max_tokens=8192,
            temperature=0.5
        )
        
        # æ•´ç†è¡Œä¸šä¿¡æ¯æœç´¢ç»“æœ
        search_results_file = os.path.join(self.m.industry_dir, "all_search_results.json")
        with open(search_results_file, 'r', encoding='utf-8') as f:
            all_search_results = json.load(f)
        search_res = ""
        for company, results in all_search_results.items():
            search_res += f"ã€{company}æœç´¢ä¿¡æ¯å¼€å§‹ã€‘\n"
            for result in results:
                search_res += f"æ ‡é¢˜: {result.get('title', 'æ— æ ‡é¢˜')}\n"
                search_res += f"é“¾æ¥: {result.get('href', 'æ— é“¾æ¥')}\n"
                search_res += f"æ‘˜è¦: {result.get('body', 'æ— æ‘˜è¦')}\n"
                search_res += "----\n"
            search_res += f"ã€{company}æœç´¢ä¿¡æ¯ç»“æŸã€‘\n\n"
        
        # ä¿å­˜é˜¶æ®µä¸€ç»“æœ
        merged_results = context.get("merged_results", {})
        sensetime_valuation_report = context.get("sensetime_valuation_report", None)
        formatted_report = format_final_reports(merged_results)
        
        # ç»Ÿä¸€ä¿å­˜ä¸ºmarkdown
        md_output_file = f"è´¢åŠ¡ç ”æŠ¥æ±‡æ€»_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        with open(md_output_file, 'w', encoding='utf-8') as f:
            f.write(f"# å…¬å¸åŸºç¡€ä¿¡æ¯\n\n## æ•´ç†åå…¬å¸ä¿¡æ¯\n\n{company_infos}\n\n")
            f.write(f"# è‚¡æƒä¿¡æ¯åˆ†æ\n\n{shareholder_analysis}\n\n")
            f.write(f"# è¡Œä¸šä¿¡æ¯æœç´¢ç»“æœ\n\n{search_res}\n\n")
            f.write(f"# è´¢åŠ¡æ•°æ®åˆ†æä¸ä¸¤ä¸¤å¯¹æ¯”\n\n{formatted_report}\n\n")
            if sensetime_valuation_report and isinstance(sensetime_valuation_report, dict):
                f.write(f"# å•†æ±¤ç§‘æŠ€ä¼°å€¼ä¸é¢„æµ‹åˆ†æ\n\n{sensetime_valuation_report.get('final_report', 'æœªç”ŸæˆæŠ¥å‘Š')}\n\n")
        
        print(f"\nâœ… ç¬¬ä¸€é˜¶æ®µå®Œæˆï¼åŸºç¡€åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {md_output_file}")
        
        # å­˜å‚¨ç»“æœä¾›ç¬¬äºŒé˜¶æ®µä½¿ç”¨
        self.analysis_results = {
            'md_file': md_output_file,
            'company_infos': company_infos,
            'shareholder_analysis': shareholder_analysis,
            'search_res': search_res,
            'formatted_report': formatted_report,
            'sensetime_valuation_report': sensetime_valuation_report
        }
        return md_output_file
    


    #### REPORT GENERATION ACTIONS ####
    def deep_report_generation(self, context):
        """ç¬¬äºŒé˜¶æ®µï¼šæ·±åº¦ç ”æŠ¥ç”Ÿæˆ"""
        print("\n" + "="*80)
        print("ğŸš€ å¼€å§‹ç¬¬äºŒé˜¶æ®µï¼šæ·±åº¦ç ”æŠ¥ç”Ÿæˆ")
        print("="*80)
        
        # å¤„ç†å›¾ç‰‡è·¯å¾„
        print("ğŸ–¼ï¸ å¤„ç†å›¾ç‰‡è·¯å¾„...")
        md_file_path = context.get("get_analysis_report", self.default_report_path)
        new_md_path = md_file_path.replace('.md', '_images.md')
        images_dir = os.path.join(os.path.dirname(md_file_path), 'images')
        extract_images_from_markdown(md_file_path, images_dir, new_md_path)
        
        # åŠ è½½æŠ¥å‘Šå†…å®¹
        report_content = load_report_content(new_md_path)
        background = get_background()
        
        # ç”Ÿæˆå¤§çº²
        print("\nğŸ“‹ ç”ŸæˆæŠ¥å‘Šå¤§çº²...")
        parts = generate_outline(self.llm, background, report_content)
        
        # åˆ†æ®µç”Ÿæˆæ·±åº¦ç ”æŠ¥
        print("\nâœï¸ å¼€å§‹åˆ†æ®µç”Ÿæˆæ·±åº¦ç ”æŠ¥...")
        full_report = ['# å•†æ±¤ç§‘æŠ€å…¬å¸ç ”æŠ¥\n']
        prev_content = ''
        
        for idx, part in enumerate(parts):
            part_title = part.get('part_title', f'éƒ¨åˆ†{idx+1}')
            print(f"\n  æ­£åœ¨ç”Ÿæˆï¼š{part_title}")
            is_last = (idx == len(parts) - 1)
            section_text = generate_section(
                self.llm, part_title, prev_content, background, report_content, is_last
            )
            full_report.append(section_text)
            print(f"  âœ… å·²å®Œæˆï¼š{part_title}")
            prev_content = '\n'.join(full_report)
        
        # ä¿å­˜æœ€ç»ˆæŠ¥å‘Š
        final_report = '\n\n'.join(full_report)
        output_file = f"æ·±åº¦è´¢åŠ¡ç ”æŠ¥åˆ†æ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        save_markdown(final_report, output_file)
        
        # æ ¼å¼åŒ–å’Œè½¬æ¢
        print("\nğŸ¨ æ ¼å¼åŒ–æŠ¥å‘Š...")
        format_markdown(output_file)
        
        print("\nğŸ“„ è½¬æ¢ä¸ºWordæ–‡æ¡£...")
        convert_to_docx(output_file)
        
        return {"deep_report_file": output_file, "status": "completed"}

    #### è¡Œä¸šç ”æŠ¥æ•°æ®æ”¶é›†å·¥å…· ####
    def get_industry_overview(self, context):
        """è·å–è¡Œä¸šæ¦‚å†µ"""
        industry_name = self.p.get_config().get("industry", "äººå·¥æ™ºèƒ½")
        print(f"ğŸ” æ”¶é›†è¡Œä¸šæ¦‚å†µï¼š{industry_name}")
        return self.industry_collector.get_industry_overview(industry_name)
    
    def get_industry_chain_analysis(self, context):
        """è·å–äº§ä¸šé“¾åˆ†æ"""
        industry_name = self.p.get_config().get("industry", "äººå·¥æ™ºèƒ½")
        print(f"ğŸ”— åˆ†æäº§ä¸šé“¾ï¼š{industry_name}")
        return self.industry_collector.get_industry_chain_analysis(industry_name)
    
    def get_industry_policy_impact(self, context):
        """è·å–è¡Œä¸šæ”¿ç­–å½±å“"""
        industry_name = self.p.get_config().get("industry", "äººå·¥æ™ºèƒ½")
        print(f"ğŸ“œ æ”¶é›†æ”¿ç­–å½±å“ï¼š{industry_name}")
        return self.industry_collector.get_industry_policy_impact(industry_name)
    
    def get_industry_technology_trends(self, context):
        """è·å–è¡Œä¸šæŠ€æœ¯å‘å±•è¶‹åŠ¿"""
        industry_name = self.p.get_config().get("industry", "äººå·¥æ™ºèƒ½")
        print(f"ğŸš€ åˆ†ææŠ€æœ¯è¶‹åŠ¿ï¼š{industry_name}")
        return self.industry_collector.get_industry_technology_trends(industry_name)
    
    def get_industry_association_reports(self, context):
        """è·å–è¡Œä¸šåä¼šæŠ¥å‘Š"""
        industry_name = self.p.get_config().get("industry", "äººå·¥æ™ºèƒ½")
        print(f"ğŸ“Š æ”¶é›†åä¼šæŠ¥å‘Šï¼š{industry_name}")
        return self.industry_collector.get_industry_association_reports(industry_name)
    
    def get_industry_market_scale(self, context):
        """è·å–è¡Œä¸šå¸‚åœºè§„æ¨¡"""
        industry_name = self.p.get_config().get("industry", "äººå·¥æ™ºèƒ½")
        print(f"ğŸ“ˆ åˆ†æå¸‚åœºè§„æ¨¡ï¼š{industry_name}")
        return self.industry_collector.get_industry_market_scale(industry_name)
    
    def get_leading_companies_data(self, context):
        """è·å–è¡Œä¸šé¾™å¤´ä¼ä¸šæ•°æ®"""
        industry_name = self.p.get_config().get("industry", "äººå·¥æ™ºèƒ½")
        print(f"ğŸ¢ æ”¶é›†é¾™å¤´ä¼ä¸šæ•°æ®ï¼š{industry_name}")
        
        # æœç´¢è¡Œä¸šé¾™å¤´ä¼ä¸š
        search_engine = SearchEngine("sogou")
        search_query = f"{industry_name} é¾™å¤´ä¼ä¸š ä¸Šå¸‚å…¬å¸ æ’å"
        search_results = list(search_engine.search(search_query, max_results=10))

        # ä¿å­˜æœç´¢ç»“æœ
        filename = f"{industry_name}_leading_companies.json"
        filepath = os.path.join(self.m.industry_dir, filename)
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(search_results, f, ensure_ascii=False, indent=2)
        
        return search_results

    #### å®è§‚ç»æµæ•°æ®æ”¶é›†å·¥å…· ####
    def get_gdp_data(self, context):
        """è·å–GDPæ•°æ®"""
        country = self.p.get_config().get("country", "ä¸­å›½")
        print(f"ğŸ“Š æ”¶é›†GDPæ•°æ®ï¼š{country}")
        return self.macro_collector.get_gdp_data(country)
    
    def get_cpi_data(self, context):
        """è·å–CPIæ•°æ®"""
        country = self.p.get_config().get("country", "ä¸­å›½")
        print(f"ğŸ’° æ”¶é›†CPIæ•°æ®ï¼š{country}")
        return self.macro_collector.get_cpi_data(country)
    
    def get_interest_rate_data(self, context):
        """è·å–åˆ©ç‡æ•°æ®"""
        country = self.p.get_config().get("country", "ä¸­å›½")
        print(f"ğŸ“ˆ æ”¶é›†åˆ©ç‡æ•°æ®ï¼š{country}")
        return self.macro_collector.get_interest_rate_data(country)
    
    def get_exchange_rate_data(self, context):
        """è·å–æ±‡ç‡æ•°æ®"""
        base_currency = self.p.get_config().get("base_currency", "äººæ°‘å¸")
        target_currency = self.p.get_config().get("target_currency", "ç¾å…ƒ")
        print(f"ğŸ’± æ”¶é›†æ±‡ç‡æ•°æ®ï¼š{base_currency}-{target_currency}")
        return self.macro_collector.get_exchange_rate_data(base_currency, target_currency)
    
    def get_federal_reserve_data(self, context):
        """è·å–ç¾è”å‚¨æ•°æ®"""
        print("ğŸ¦ æ”¶é›†ç¾è”å‚¨åˆ©ç‡æ•°æ®")
        return self.macro_collector.get_federal_reserve_data()
    
    def get_policy_reports(self, context):
        """è·å–æ”¿ç­–æŠ¥å‘Š"""
        country = self.p.get_config().get("country", "ä¸­å›½")
        print(f"ğŸ“œ æ”¶é›†æ”¿ç­–æŠ¥å‘Šï¼š{country}")
        return self.macro_collector.get_policy_reports(country)
    
    def get_macro_industry_impact(self, context):
        """è·å–å®è§‚å¯¹è¡Œä¸šçš„å½±å“"""
        industry_name = self.p.get_config().get("industry", "ç§‘æŠ€è¡Œä¸š")
        print(f"ğŸŒ åˆ†æå®è§‚å¯¹è¡Œä¸šå½±å“ï¼š{industry_name}")
        return self.macro_collector.get_industry_policy_impact(industry_name)

    def _gather_industry_data(self, context, industry_name):
        """æ•´åˆä¹‹å‰æ”¶é›†çš„è¡Œä¸šæ•°æ®"""
        collected_data = {}
        
        # ä»contextä¸­è·å–æ•°æ®
        overview_data = context.get("get_industry_overview", {})
        chain_data = context.get("get_industry_chain_analysis", {})
        leading_companies_data = context.get("get_leading_companies_data", [])
        market_scale_data = context.get("get_industry_market_scale", {})
        policy_data = context.get("get_industry_policy_impact", {})
        tech_trends_data = context.get("get_industry_technology_trends", {})
        association_data = context.get("get_industry_association_reports", {})
        
        # ä»æ–‡ä»¶ä¸­åŠ è½½æ•°æ®ï¼ˆå¦‚æœcontextä¸­æ²¡æœ‰ï¼‰
        if not overview_data:
            overview_file = os.path.join(self.m.industry_dir, f"{industry_name}_overview.json")
            if os.path.exists(overview_file):
                with open(overview_file, 'r', encoding='utf-8') as f:
                    overview_data = json.load(f)
        
        if not chain_data:
            chain_file = os.path.join(self.m.industry_dir, f"{industry_name}_chain_analysis.json")
            if os.path.exists(chain_file):
                with open(chain_file, 'r', encoding='utf-8') as f:
                    chain_data = json.load(f)
        
        if not leading_companies_data:
            companies_file = os.path.join(self.m.industry_dir, f"{industry_name}_leading_companies.json")
            if os.path.exists(companies_file):
                with open(companies_file, 'r', encoding='utf-8') as f:
                    leading_companies_data = json.load(f)
        
        if not market_scale_data:
            market_file = os.path.join(self.m.industry_dir, f"{industry_name}_market_scale.json")
            if os.path.exists(market_file):
                with open(market_file, 'r', encoding='utf-8') as f:
                    market_scale_data = json.load(f)
        
        # æ•´ç†æ•°æ®
        if overview_data:
            collected_data['overview'] = self._format_search_results(overview_data, "è¡Œä¸šæ¦‚å†µ")
        
        if chain_data:
            collected_data['chain_analysis'] = self._format_search_results(chain_data, "äº§ä¸šé“¾åˆ†æ")
        
        if leading_companies_data:
            collected_data['leading_companies'] = self._format_search_results_list(leading_companies_data, "é¾™å¤´ä¼ä¸š")
        
        if market_scale_data:
            collected_data['market_scale'] = self._format_search_results(market_scale_data, "å¸‚åœºè§„æ¨¡")
        
        if policy_data:
            collected_data['policy_impact'] = self._format_search_results(policy_data, "æ”¿ç­–å½±å“")
        
        if tech_trends_data:
            collected_data['tech_trends'] = self._format_search_results(tech_trends_data, "æŠ€æœ¯è¶‹åŠ¿")
            
        if association_data:
            collected_data['association_reports'] = self._format_search_results(association_data, "åä¼šæŠ¥å‘Š")
        
        return collected_data
    
    def _format_search_results(self, data, data_type):
        """æ ¼å¼åŒ–æœç´¢ç»“æœæ•°æ®"""
        if not data:
            return f"æš‚æ— {data_type}æ•°æ®"
        
        formatted_text = f"\n=== {data_type} ===\n"
        
        for query, results in data.items():
            formatted_text += f"\nã€{query}ã€‘\n"
            for i, result in enumerate(results[:3], 1):  # åªå–å‰3ä¸ªç»“æœ
                title = result.get('title', 'æ— æ ‡é¢˜')
                description = result.get('description', result.get('body', 'æ— æè¿°'))
                url = result.get('url', result.get('href', ''))
                
                formatted_text += f"{i}. {title}\n"
                if description:
                    # æˆªå–æè¿°çš„å‰200å­—ç¬¦
                    desc_short = description[:200] + "..." if len(description) > 200 else description
                    formatted_text += f"   æ‘˜è¦: {desc_short}\n"
                if url:
                    formatted_text += f"   é“¾æ¥: {url}\n"
                formatted_text += "\n"
        
        return formatted_text
    
    def _format_search_results_list(self, data_list, data_type):
        """æ ¼å¼åŒ–æœç´¢ç»“æœåˆ—è¡¨"""
        if not data_list:
            return f"æš‚æ— {data_type}æ•°æ®"
        
        formatted_text = f"\n=== {data_type} ===\n"
        
        for i, result in enumerate(data_list[:5], 1):  # åªå–å‰5ä¸ªç»“æœ
            title = result.get('title', 'æ— æ ‡é¢˜')
            description = result.get('description', result.get('body', 'æ— æè¿°'))
            url = result.get('url', result.get('href', ''))
            
            formatted_text += f"{i}. {title}\n"
            if description:
                desc_short = description[:200] + "..." if len(description) > 200 else description
                formatted_text += f"   æ‘˜è¦: {desc_short}\n"
            if url:
                formatted_text += f"   é“¾æ¥: {url}\n"
            formatted_text += "\n"
        
        return formatted_text

    #### åˆ†æå·¥å…·æ‰©å±• ####
    def analyze_industry_structure(self, context):
        """åˆ†æè¡Œä¸šç»“æ„"""
        print("ğŸ—ï¸ åˆ†æè¡Œä¸šç»“æ„")
        industry_name = self.p.get_config().get("industry", "äººå·¥æ™ºèƒ½")
        
        # æ•´åˆä¹‹å‰æ”¶é›†çš„æ•°æ®
        collected_data = self._gather_industry_data(context, industry_name)
        
        if not collected_data:
            raise ValueError("ç¼ºå°‘è¡Œä¸šæ•°æ®ï¼Œè¯·å…ˆæ‰§è¡Œæ•°æ®æ”¶é›†æ­¥éª¤")
        
        # æ„å»ºåŒ…å«å®é™…æ•°æ®çš„åˆ†æprompt
        analysis_prompt = f"""
        åŸºäºä»¥ä¸‹æ”¶é›†åˆ°çš„{industry_name}è¡Œä¸šå®é™…æ•°æ®ï¼Œè¯·è¿›è¡Œæ·±å…¥çš„è¡Œä¸šç»“æ„åˆ†æï¼š

        === è¡Œä¸šæ¦‚å†µæ•°æ® ===
        {collected_data.get('overview', 'æš‚æ— æ•°æ®')}

        === äº§ä¸šé“¾æ•°æ® ===
        {collected_data.get('chain_analysis', 'æš‚æ— æ•°æ®')}

        === é¾™å¤´ä¼ä¸šæ•°æ® ===
        {collected_data.get('leading_companies', 'æš‚æ— æ•°æ®')}

        === å¸‚åœºè§„æ¨¡æ•°æ® ===
        {collected_data.get('market_scale', 'æš‚æ— æ•°æ®')}

        è¯·åŸºäºä»¥ä¸ŠçœŸå®æ•°æ®åˆ†æï¼š
        1. è¡Œä¸šå‘å±•é˜¶æ®µå’Œæˆç†Ÿåº¦ï¼ˆå¼•ç”¨å…·ä½“æ•°æ®æ”¯æ’‘ï¼‰
        2. å¸‚åœºé›†ä¸­åº¦å’Œç«äº‰æ ¼å±€ï¼ˆåŸºäºé¾™å¤´ä¼ä¸šå’Œå¸‚åœºæ•°æ®ï¼‰
        3. äº§ä¸šé“¾åˆ†å·¥å’Œä»·å€¼åˆ†å¸ƒï¼ˆåŸºäºäº§ä¸šé“¾æ•°æ®ï¼‰
        4. ä¸»è¦å‚ä¸è€…å’Œå•†ä¸šæ¨¡å¼ï¼ˆåŸºäºä¼ä¸šæ•°æ®ï¼‰
        
        è¯·ç¡®ä¿åˆ†æç»“è®ºæœ‰æ•°æ®æ”¯æ’‘ï¼Œé¿å…ç©ºæ³›æè¿°ã€‚
        """
        
        return self.llm.call(analysis_prompt, system_prompt="ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è¡Œä¸šåˆ†æå¸ˆï¼Œè¯·åŸºäºæä¾›çš„çœŸå®æ•°æ®è¿›è¡Œåˆ†æ")
    
    def analyze_industry_trends(self, context):
        """åˆ†æè¡Œä¸šå‘å±•è¶‹åŠ¿"""
        print("ğŸ“ˆ åˆ†æè¡Œä¸šå‘å±•è¶‹åŠ¿")
        industry_name = self.p.get_config().get("industry", "äººå·¥æ™ºèƒ½")
        
        # æ•´åˆä¹‹å‰æ”¶é›†çš„æ•°æ®
        collected_data = self._gather_industry_data(context, industry_name)
        
        if not collected_data:
            return "ç¼ºå°‘è¡Œä¸šæ•°æ®ï¼Œè¯·å…ˆæ‰§è¡Œæ•°æ®æ”¶é›†æ­¥éª¤"
        
        # æ„å»ºåŒ…å«å®é™…æ•°æ®çš„åˆ†æprompt
        analysis_prompt = f"""
        åŸºäºä»¥ä¸‹æ”¶é›†åˆ°çš„{industry_name}è¡Œä¸šå®é™…æ•°æ®ï¼Œè¯·è¿›è¡Œæ·±å…¥çš„è¡Œä¸šå‘å±•è¶‹åŠ¿åˆ†æï¼š

        === æŠ€æœ¯è¶‹åŠ¿æ•°æ® ===
        {collected_data.get('tech_trends', 'æš‚æ— æ•°æ®')}

        === å¸‚åœºè§„æ¨¡æ•°æ® ===
        {collected_data.get('market_scale', 'æš‚æ— æ•°æ®')}

        === æ”¿ç­–å½±å“æ•°æ® ===
        {collected_data.get('policy_impact', 'æš‚æ— æ•°æ®')}

        === åä¼šæŠ¥å‘Šæ•°æ® ===
        {collected_data.get('association_reports', 'æš‚æ— æ•°æ®')}

        è¯·åŸºäºä»¥ä¸ŠçœŸå®æ•°æ®åˆ†æï¼š
        1. æŠ€æœ¯å‘å±•è¶‹åŠ¿å’Œåˆ›æ–°æ–¹å‘ï¼ˆå¼•ç”¨å…·ä½“æŠ€æœ¯æ•°æ®ï¼‰
        2. å¸‚åœºè§„æ¨¡å¢é•¿é¢„æµ‹ï¼ˆåŸºäºçœŸå®å¸‚åœºæ•°æ®ï¼‰
        3. æ”¿ç­–ç¯å¢ƒå˜åŒ–å½±å“ï¼ˆåŸºäºæ”¿ç­–æ•°æ®åˆ†æï¼‰
        4. æœªæ¥3-5å¹´å‘å±•å‰æ™¯ï¼ˆç»¼åˆå„é¡¹æ•°æ®é¢„æµ‹ï¼‰
        
        è¯·ç¡®ä¿åˆ†æç»“è®ºæœ‰æ•°æ®æ”¯æ’‘ï¼Œé¿å…ç©ºæ³›æè¿°ã€‚
        """
        
        return self.llm.call(analysis_prompt, system_prompt="ä½ æ˜¯ä¸€ä½èµ„æ·±çš„è¡Œä¸šç ”ç©¶ä¸“å®¶ï¼Œè¯·åŸºäºæä¾›çš„çœŸå®æ•°æ®è¿›è¡Œåˆ†æ")
    
    def _gather_macro_data(self, context, country="ä¸­å›½"):
        """æ•´åˆä¹‹å‰æ”¶é›†çš„å®è§‚ç»æµæ•°æ®"""
        collected_data = {}
        
        # ä»contextä¸­è·å–æ•°æ®
        gdp_data = context.get("get_gdp_data", {})
        cpi_data = context.get("get_cpi_data", {})
        interest_rate_data = context.get("get_interest_rate_data", {})
        exchange_rate_data = context.get("get_exchange_rate_data", {})
        fed_data = context.get("get_federal_reserve_data", {})
        policy_data = context.get("get_policy_reports", {})
        industry_impact_data = context.get("get_macro_industry_impact", {})
        
        # ä»æ–‡ä»¶ä¸­åŠ è½½æ•°æ®ï¼ˆå¦‚æœcontextä¸­æ²¡æœ‰ï¼‰
        if not gdp_data:
            gdp_file = os.path.join("./data", "macro", f"{country}_gdp_data.json")
            if os.path.exists(gdp_file):
                with open(gdp_file, 'r', encoding='utf-8') as f:
                    gdp_data = json.load(f)
        
        if not cpi_data:
            cpi_file = os.path.join("./data", "macro", f"{country}_cpi_data.json")
            if os.path.exists(cpi_file):
                with open(cpi_file, 'r', encoding='utf-8') as f:
                    cpi_data = json.load(f)

        if not interest_rate_data:
            interest_rate_file = os.path.join("./data", "macro", f"{country}_interest_rate_data.json")
            if os.path.exists(interest_rate_file):
                with open(interest_rate_file, 'r', encoding='utf-8') as f:
                    interest_rate_data = json.load(f)
        
        if not exchange_rate_data:
            exchange_rate_file = os.path.join("./data", "macro", f"exchange_rate.json")
            if os.path.exists(exchange_rate_file):
                with open(exchange_rate_file, 'r', encoding='utf-8') as f:
                    exchange_rate_data = json.load(f)

        if not fed_data:
            fed_rate_file = os.path.join("./data", "macro", "fed_interest_rate_data.json")
            if os.path.exists(fed_rate_file):
                with open(fed_rate_file, 'r', encoding='utf-8') as f:
                    fed_data = json.load(f)

        if not policy_data:
            policy_file = os.path.join("./data", "macro", f"{country}_policy_reports.json")
            if os.path.exists(policy_file):
                with open(policy_file, 'r', encoding='utf-8') as f:
                    policy_data = json.load(f)
        
        if not industry_impact_data:
            industry_impact_file = os.path.join("./data", "macro", "policy_impact.json")
            if os.path.exists(industry_impact_file):
                with open(industry_impact_file, 'r', encoding='utf-8') as f:
                    industry_impact_data = json.load(f)

        # æ•´ç†æ•°æ®
        if gdp_data:
            collected_data['gdp'] = self._format_search_results(gdp_data, "GDPæ•°æ®")
        
        if cpi_data:
            collected_data['cpi'] = self._format_search_results(cpi_data, "CPIæ•°æ®")
        
        if interest_rate_data:
            collected_data['interest_rate'] = self._format_search_results(interest_rate_data, "åˆ©ç‡æ•°æ®")
        
        if exchange_rate_data:
            collected_data['exchange_rate'] = self._format_search_results(exchange_rate_data, "æ±‡ç‡æ•°æ®")
        
        if fed_data:
            collected_data['federal_reserve'] = self._format_search_results(fed_data, "ç¾è”å‚¨æ•°æ®")
        
        if policy_data:
            collected_data['policy'] = self._format_search_results(policy_data, "æ”¿ç­–æŠ¥å‘Š")
        
        if industry_impact_data:
            collected_data['industry_impact'] = self._format_search_results(industry_impact_data, "è¡Œä¸šå½±å“")
        
        return collected_data

    def analyze_macro_trends(self, context):
        """åˆ†æå®è§‚ç»æµè¶‹åŠ¿"""
        print("ğŸŒ åˆ†æå®è§‚ç»æµè¶‹åŠ¿")
        country = self.p.get_config().get("country", "ä¸­å›½")
        
        # æ•´åˆä¹‹å‰æ”¶é›†çš„æ•°æ®
        collected_data = self._gather_macro_data(context, country)
        
        if not collected_data:
            return "ç¼ºå°‘å®è§‚ç»æµæ•°æ®ï¼Œè¯·å…ˆæ‰§è¡Œæ•°æ®æ”¶é›†æ­¥éª¤"
        
        # æ„å»ºåŒ…å«å®é™…æ•°æ®çš„åˆ†æprompt
        analysis_prompt = f"""
        åŸºäºä»¥ä¸‹æ”¶é›†åˆ°çš„{country}å®è§‚ç»æµå®é™…æ•°æ®ï¼Œè¯·è¿›è¡Œæ·±å…¥çš„å®è§‚ç»æµè¶‹åŠ¿åˆ†æï¼š

        === GDPæ•°æ® ===
        {collected_data.get('gdp', 'æš‚æ— æ•°æ®')}

        === CPIé€šèƒ€æ•°æ® ===
        {collected_data.get('cpi', 'æš‚æ— æ•°æ®')}

        === åˆ©ç‡æ•°æ® ===
        {collected_data.get('interest_rate', 'æš‚æ— æ•°æ®')}

        === æ±‡ç‡æ•°æ® ===
        {collected_data.get('exchange_rate', 'æš‚æ— æ•°æ®')}

        === ç¾è”å‚¨æ”¿ç­–æ•°æ® ===
        {collected_data.get('federal_reserve', 'æš‚æ— æ•°æ®')}

        === æ”¿ç­–æŠ¥å‘Šæ•°æ® ===
        {collected_data.get('policy', 'æš‚æ— æ•°æ®')}

        è¯·åŸºäºä»¥ä¸ŠçœŸå®æ•°æ®åˆ†æï¼š
        1. GDPå¢é•¿åŠ¨åŠ›å’Œç»“æ„å˜åŒ–ï¼ˆå¼•ç”¨å…·ä½“GDPæ•°æ®ï¼‰
        2. é€šèƒ€å‹åŠ›å’Œè´§å¸æ”¿ç­–èµ°å‘ï¼ˆåŸºäºCPIå’Œåˆ©ç‡æ•°æ®ï¼‰
        3. æ±‡ç‡ç¯å¢ƒå¯¹ç»æµçš„å½±å“ï¼ˆåŸºäºæ±‡ç‡æ•°æ®åˆ†æï¼‰
        4. å›½é™…ç¯å¢ƒå¯¹å›½å†…ç»æµçš„å½±å“ï¼ˆç»“åˆç¾è”å‚¨æ”¿ç­–æ•°æ®ï¼‰
        
        è¯·ç¡®ä¿åˆ†æç»“è®ºæœ‰æ•°æ®æ”¯æ’‘ï¼Œé¿å…ç©ºæ³›æè¿°ã€‚
        """
        
        return self.llm.call(analysis_prompt, system_prompt="ä½ æ˜¯ä¸€ä½å®è§‚ç»æµåˆ†æä¸“å®¶ï¼Œè¯·åŸºäºæä¾›çš„çœŸå®æ•°æ®è¿›è¡Œåˆ†æ")
    
    def analyze_policy_impact(self, context):
        """åˆ†ææ”¿ç­–å½±å“"""
        print("ğŸ“œ åˆ†ææ”¿ç­–å½±å“")
        country = self.p.get_config().get("country", "ä¸­å›½")
        industry_name = self.p.get_config().get("industry", "")
        
        # æ•´åˆå®è§‚æ”¿ç­–æ•°æ®
        macro_data = self._gather_macro_data(context, country)
        
        # å¦‚æœæ˜¯è¡Œä¸šç ”æŠ¥ï¼Œè¿˜è¦æ•´åˆè¡Œä¸šæ”¿ç­–æ•°æ®
        industry_data = {}
        if industry_name and self.current_report_type == ReportType.INDUSTRY:
            industry_data = self._gather_industry_data(context, industry_name)
        
        if not macro_data and not industry_data:
            return "ç¼ºå°‘æ”¿ç­–æ•°æ®ï¼Œè¯·å…ˆæ‰§è¡Œæ•°æ®æ”¶é›†æ­¥éª¤"
        
        # æ„å»ºåŒ…å«å®é™…æ•°æ®çš„åˆ†æprompt
        analysis_prompt = f"""
        åŸºäºä»¥ä¸‹æ”¶é›†åˆ°çš„æ”¿ç­–æ•°æ®ï¼Œè¯·åˆ†æå½“å‰æ”¿ç­–ç¯å¢ƒå¯¹ç»æµå’Œç›¸å…³è¡Œä¸šçš„å½±å“ï¼š

        === å®è§‚æ”¿ç­–æ•°æ® ===
        {macro_data.get('policy', 'æš‚æ— å®è§‚æ”¿ç­–æ•°æ®')}

        === GDPç›¸å…³æ”¿ç­–å½±å“ ===
        {macro_data.get('gdp', 'æš‚æ— GDPæ•°æ®')}

        === è´§å¸æ”¿ç­–æ•°æ® ===
        {macro_data.get('interest_rate', 'æš‚æ— åˆ©ç‡æ”¿ç­–æ•°æ®')}
        {macro_data.get('federal_reserve', 'æš‚æ— ç¾è”å‚¨æ”¿ç­–æ•°æ®')}
        """
        
        # å¦‚æœæœ‰è¡Œä¸šæ•°æ®ï¼Œæ·»åŠ è¡Œä¸šæ”¿ç­–éƒ¨åˆ†
        if industry_data:
            analysis_prompt += f"""
        === è¡Œä¸šæ”¿ç­–æ•°æ® ===
        {industry_data.get('policy_impact', 'æš‚æ— è¡Œä¸šæ”¿ç­–æ•°æ®')}
        """
        
        analysis_prompt += """
        è¯·åŸºäºä»¥ä¸ŠçœŸå®æ•°æ®åˆ†æï¼š
        1. è´¢æ”¿æ”¿ç­–çš„åˆºæ¿€æ•ˆæœå’ŒæŒç»­æ€§ï¼ˆå¼•ç”¨å…·ä½“æ”¿ç­–æ•°æ®ï¼‰
        2. è´§å¸æ”¿ç­–çš„ä¼ å¯¼æœºåˆ¶å’Œæ•ˆæœï¼ˆåŸºäºåˆ©ç‡å’ŒæµåŠ¨æ€§æ•°æ®ï¼‰
        3. è¡Œä¸šæ”¿ç­–å¯¹ç‰¹å®šé¢†åŸŸçš„æ‰¶æŒåŠ›åº¦ï¼ˆå¦‚æœ‰è¡Œä¸šæ•°æ®ï¼‰
        4. æ”¿ç­–åè°ƒæ€§å’Œæœªæ¥æ”¿ç­–é¢„æœŸï¼ˆç»¼åˆå„é¡¹æ”¿ç­–æ•°æ®ï¼‰
        
        è¯·ç¡®ä¿åˆ†æç»“è®ºæœ‰æ•°æ®æ”¯æ’‘ï¼Œé¿å…ç©ºæ³›æè¿°ã€‚
        """
        
        return self.llm.call(analysis_prompt, system_prompt="ä½ æ˜¯ä¸€ä½æ”¿ç­–åˆ†æä¸“å®¶ï¼Œè¯·åŸºäºæä¾›çš„çœŸå®æ•°æ®è¿›è¡Œåˆ†æ")

    #### æŠ¥å‘Šç”Ÿæˆå·¥å…·æ‰©å±• ####
    def generate_industry_report(self, context):
        """åˆ†æ®µç”Ÿæˆè¡Œä¸šç ”æŠ¥"""
        print("ğŸ“ åˆ†æ®µç”Ÿæˆè¡Œä¸šç ”æŠ¥")
        industry_name = self.p.get_config().get("industry", "äººå·¥æ™ºèƒ½")

        # æå–åˆ†æç»“æœå’Œæ•°æ®
        industry_analysis = context.get("analyze_industry_structure", "")
        trends_analysis = context.get("analyze_industry_trends", "")
        collected_data = self._gather_industry_data(context, industry_name)

        def call_llm_section(title, instruction, content):
            prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è¡Œä¸šç ”ç©¶åˆ†æå¸ˆï¼Œè¯·æ ¹æ®ä»¥ä¸‹å†…å®¹æ’°å†™ã€Š{industry_name}ã€‹è¡Œä¸šç ”æŠ¥ä¸­çš„ã€{title}ã€‘éƒ¨åˆ†ã€‚

ã€å†™ä½œè¦æ±‚ã€‘
- {instruction}
- ä½¿ç”¨ä¸“ä¸šæœ¯è¯­ï¼Œé€»è¾‘ä¸¥å¯†ï¼Œè¯­è¨€ç²¾ç‚¼ï¼Œç¯‡å¹…æ§åˆ¶åœ¨500-800å­—ã€‚

ã€åŸå§‹åˆ†ææ•°æ®ã€‘
{content}
"""
            return self.llm.call(prompt, system_prompt="ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è¡Œä¸šç ”ç©¶åˆ†æå¸ˆï¼Œæ“…é•¿æ’°å†™æ·±åº¦è¡Œä¸šç ”æŠ¥ã€‚")

        # æ¯æ®µç”Ÿæˆå†…å®¹
        sections = []

        sections.append(("è¡Œä¸šæ¦‚å†µ", call_llm_section(
            "è¡Œä¸šæ¦‚å†µ", "ä»‹ç»è¡Œä¸šæ•´ä½“æƒ…å†µï¼ŒåŒ…æ‹¬å‘å±•èƒŒæ™¯ã€ä¸»è¦åº”ç”¨é¢†åŸŸä¸ç°çŠ¶",
            collected_data.get('overview', 'æš‚æ— æ•°æ®'))))

        sections.append(("äº§ä¸šé“¾åˆ†æ", call_llm_section(
            "äº§ä¸šé“¾åˆ†æ", "ä»ä¸Šæ¸¸ã€ä¸­æ¸¸ã€ä¸‹æ¸¸ä¸‰ä¸ªç¯èŠ‚åˆ†æè¡Œä¸šçš„äº§ä¸šé“¾ç»“æ„",
            industry_analysis)))

        sections.append(("å¸‚åœºè§„æ¨¡ä¸ç«äº‰æ ¼å±€", call_llm_section(
            "å¸‚åœºè§„æ¨¡ä¸ç«äº‰æ ¼å±€", "è¯´æ˜å¸‚åœºè§„æ¨¡ã€ä¸»è¦ä¼ä¸šã€ç«äº‰æ€åŠ¿",
            collected_data.get('market_scale', '') + "\n" + collected_data.get('leading_companies', ''))))

        sections.append(("æŠ€æœ¯å‘å±•è¶‹åŠ¿", call_llm_section(
            "æŠ€æœ¯å‘å±•è¶‹åŠ¿", "æç‚¼è¡Œä¸šä¸­çš„æ ¸å¿ƒæŠ€æœ¯æ¼”è¿›è·¯å¾„å’Œåˆ›æ–°æ–¹å‘",
            trends_analysis)))

        sections.append(("æ”¿ç­–ç¯å¢ƒåˆ†æ", call_llm_section(
            "æ”¿ç­–ç¯å¢ƒåˆ†æ", "æ¢³ç†æ”¿ç­–æ³•è§„ã€è¡¥è´´ç­‰å¯¹è¡Œä¸šçš„å½±å“",
            collected_data.get('policy', 'æš‚æ— æ•°æ®'))))

        sections.append(("æŠ•èµ„æœºä¼šä¸é£é™©", call_llm_section(
            "æŠ•èµ„æœºä¼šä¸é£é™©", "ç»¼åˆä»¥ä¸Šå†…å®¹ï¼Œæå‡ºæŠ•èµ„å»ºè®®å¹¶æŒ‡å‡ºæ½œåœ¨é£é™©",
            "\n".join([s[1] for s in sections[:5]]))))  # å‰5æ®µä¸ºåŸºç¡€

        # ç»„è£… Markdown æ ¼å¼ç ”æŠ¥
        report_content = f"# {industry_name}è¡Œä¸šç ”ç©¶æŠ¥å‘Š\n\n"
        for title, content in sections:
            report_content += f"## {title}\n\n{content.strip()}\n\n"

        # ä¿å­˜æ–‡ä»¶
        output_file = f"{industry_name}è¡Œä¸šç ”æŠ¥_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        save_markdown(report_content, output_file)

        return {"industry_report_file": output_file, "content": report_content}
    

    def generate_macro_report(self, context):
        """åˆ†æ®µç”Ÿæˆå®è§‚ç»æµç ”æŠ¥"""
        print("ğŸ“Š ç”Ÿæˆå®è§‚ç»æµç ”æŠ¥ï¼ˆåˆ†æ®µï¼‰")
        country = self.p.get_config().get("country", "ä¸­å›½")

        macro_trends = context.get("analyze_macro_trends", "")
        policy_impact = context.get("analyze_policy_impact", "")
        collected_data = self._gather_macro_data(context, country)

        # é™åˆ¶è¾“å…¥æ•°æ®é•¿åº¦
        def truncate(txt, maxlen=500):
            return txt[:maxlen] + "..." if len(txt) > maxlen else txt

        # åˆ†æ®µæ¨¡æ¿
        sections = [
            {
                "title": "1. å®è§‚ç»æµæ¦‚å†µ",
                "instruction": f"""ä½ æ˜¯ä¸€ä½èµ„æ·±å®è§‚åˆ†æå¸ˆï¼Œè¯·æ ¹æ®ä»¥ä¸‹ä¸­å›½å®è§‚æ•°æ®åˆ†ææ•´ä½“ç»æµçŠ¶å†µï¼š
    - GDP: {truncate(collected_data.get('gdp', 'æš‚æ— '))}
    - CPI: {truncate(collected_data.get('cpi', 'æš‚æ— '))}
    è¯·è¾“å‡ºä¸€æ®µ500å­—å·¦å³çš„åˆ†æã€‚"""
            },
            {
                "title": "2. è´§å¸æ”¿ç­–åˆ†æ",
                "instruction": f"""è¯·åˆ†æä¸­å›½å½“å‰è´§å¸æ”¿ç­–è¶‹åŠ¿ï¼ŒåŸºäºä»¥ä¸‹ä¿¡æ¯ï¼š
    - åˆ©ç‡æƒ…å†µ: {truncate(collected_data.get('interest_rate', 'æš‚æ— '))}
    - å®è§‚è¶‹åŠ¿: {truncate(macro_trends)}
    è¦æ±‚ï¼šæ¢³ç†è´§å¸æ”¿ç­–å˜åŒ–èƒŒæ™¯ï¼Œç»“åˆåˆ©ç‡æˆ–æµåŠ¨æ€§è¿›è¡Œåˆ†æã€‚"""
            },
            {
                "title": "3. è´¢æ”¿æ”¿ç­–åˆ†æ",
                "instruction": f"""è¯·åˆ†æå½“å‰è´¢æ”¿æ”¿ç­–å¯¹å®è§‚ç»æµçš„å½±å“ï¼Œæ•°æ®å‚è€ƒï¼š
    - æ”¿ç­–æ‘˜è¦: {truncate(policy_impact)}
    - æ”¿ç­–æ–‡ä»¶åŸæ–‡: {truncate(collected_data.get('policy', 'æš‚æ— '))}"""
            },
            {
                "title": "4. å›½é™…ç¯å¢ƒå½±å“",
                "instruction": f"""è¯·åˆ†æå›½é™…å®è§‚ç¯å¢ƒå¯¹ä¸­å›½çš„å½±å“ï¼ŒåŒ…æ‹¬æ±‡ç‡ã€ç¾è”å‚¨åŠ æ¯ç­‰å†…å®¹ã€‚
    - æ±‡ç‡èµ°åŠ¿: {truncate(collected_data.get('exchange_rate', 'æš‚æ— '))}"""
            },
            {
                "title": "5. è¡Œä¸šå½±å“åˆ†æ",
                "instruction": f"""ç»“åˆä¸Šé¢çš„å®è§‚åˆ†æï¼Œåˆ¤æ–­ä¸­å›½å“ªäº›è¡Œä¸šå—ç›Š/å—æŒ«ï¼Œå¹¶è¯´æ˜åŸå› ã€‚"""
            },
            {
                "title": "6. æŠ•èµ„ç­–ç•¥å»ºè®®",
                "instruction": f"""åŸºäºä¸Šè¿°å®è§‚åˆ¤æ–­ï¼Œæå‡ºå…·ä½“çš„æŠ•èµ„å»ºè®®ï¼Œæ ‡æ˜æ¨èèµ„äº§ç±»åˆ«åŠåŸå› ã€‚"""
            }
        ]

        def safe_llm_call(prompt, sys_prompt=None, retries=3):
            for i in range(retries):
                try:
                    return self.llm.call(prompt, system_prompt=sys_prompt)
                except Exception as e:
                    print(f"âš ï¸ LLMè°ƒç”¨å¤±è´¥ï¼ˆç¬¬{i+1}æ¬¡ï¼‰: {e}")
                    time.sleep(1)
            return "ã€ç”Ÿæˆå¤±è´¥ã€‘è¿æ¥é”™è¯¯"

        report_parts = []
        for i, sec in enumerate(sections):
            print(f"âœï¸ æ­£åœ¨ç”Ÿæˆ {sec['title']}")
            content = safe_llm_call(
                sec["instruction"],
                sys_prompt="ä½ æ˜¯ä¸€ä½èµ„æ·±å®è§‚ç»æµç ”ç©¶å‘˜ï¼Œè¯·è¾“å‡ºç»“æ„æ¸…æ™°ã€ä¸“ä¸šã€ç®€æ´çš„åˆ†æå†…å®¹ã€‚"
            )
            section_text = f"## {sec['title']}\n\n{content.strip()}\n"
            report_parts.append(section_text)

        # æ‹¼æ¥å®Œæ•´å†…å®¹
        full_report = "# å®è§‚ç»æµç ”æŠ¥\n\n" + "\n".join(report_parts)

        # ä¿å­˜
        output_file = f"{country}å®è§‚ç»æµç ”æŠ¥_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        save_markdown(full_report, output_file)

        print(f"âœ… æŠ¥å‘Šç”Ÿæˆå®Œæ¯•ï¼Œä¿å­˜è‡³ {output_file}")
        return {
            "macro_report_file": output_file,
            "content": full_report
        }
