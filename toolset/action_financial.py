# action_financial.py
from toolset.utils.get_financial_statements import get_all_financial_statements, save_financial_statements_to_csv
from toolset.utils.get_stock_intro import get_stock_intro, save_stock_intro_to_txt
from toolset.utils.get_shareholder_info import get_shareholder_info, get_table_content
from toolset.utils.search_engine import SearchEngine
from toolset.utils.identify_competitors import identify_competitors_with_ai
from toolset.utils.markdown_utils import save_markdown, format_markdown, convert_to_docx, extract_images_from_markdown, load_report_content, get_background, generate_outline, generate_section
from toolset.utils.analyzer import Analyzer
from toolset.utils.industry_data_collector import IndustryDataCollector
from toolset.utils.macro_data_collector import MacroDataCollector
from toolset.utils.report_type_config import ReportTypeConfig, ReportType
import time, random, os
from datetime import datetime
import glob
import json
from pathlib import Path

class FinancialActionToolset:
    def __init__(self, profile, memory, llm, llm_config):
        self.p = profile
        self.m = memory
        self.llm = llm
        self.cfg = llm_config
        # åˆå§‹åŒ–é»˜è®¤æŠ¥å‘Šè·¯å¾„
        self.reports_dir = os.path.join(self.m.data_dir, "reports")
        self.default_report_path = os.path.join(self.reports_dir, "financial_analysis_report.md")
        # Analyzer initialized
        self.analyzer = Analyzer(llm_config=llm_config, llm=llm, output_dir=self.m.data_dir, absolute_path=False)
        
        # åˆå§‹åŒ–æ–°çš„æ•°æ®æ”¶é›†å™¨
        self.industry_collector = IndustryDataCollector()
        self.macro_collector = MacroDataCollector()
        self.report_config = ReportTypeConfig()
        
        # å½“å‰ç ”æŠ¥ç±»å‹ï¼ˆä»profileé…ç½®ä¸­è·å–ï¼Œé»˜è®¤ä¸ºå…¬å¸ç ”æŠ¥ï¼‰
        self.current_report_type = self._determine_report_type()
        
        # ğŸ¯ æ–°å¢ï¼šæŠ¥å‘Šè·¯å¾„å­˜å‚¨å±æ€§
        self.generated_report_paths = {
            "company_report": None,      # å…¬å¸ç ”æŠ¥è·¯å¾„
            "industry_report": None,     # è¡Œä¸šç ”æŠ¥è·¯å¾„  
            "macro_report": None,        # å®è§‚ç ”æŠ¥è·¯å¾„
            "deep_report": None,         # æ·±åº¦ç ”æŠ¥è·¯å¾„
            "analysis_report": None,     # åˆ†ææŠ¥å‘Šè·¯å¾„
            "latest_report": None        # æœ€æ–°ç”Ÿæˆçš„æŠ¥å‘Šè·¯å¾„
        }
        
        # ç¡®ä¿æŠ¥å‘Šç›®å½•å­˜åœ¨
        os.makedirs(self.reports_dir, exist_ok=True)
        
    def _update_report_path(self, report_type: str, file_path: str):
        """æ›´æ–°æŠ¥å‘Šè·¯å¾„åˆ°ç±»å±æ€§ä¸­"""
        self.generated_report_paths[report_type] = file_path
        self.generated_report_paths["latest_report"] = file_path
        print(f"ğŸ“„ å·²ä¿å­˜{report_type}è·¯å¾„: {file_path}")
    
    def get_latest_report_path(self) -> str:
        """è·å–æœ€æ–°ç”Ÿæˆçš„æŠ¥å‘Šè·¯å¾„"""
        return self.generated_report_paths.get("latest_report")
        
    def get_report_path(self, report_type: str) -> str:
        """è·å–æŒ‡å®šç±»å‹çš„æŠ¥å‘Šè·¯å¾„"""
        return self.generated_report_paths.get(report_type)
    
    def _determine_report_type(self) -> ReportType:
        """ç¡®å®šç ”æŠ¥ç±»å‹"""
        # ä»profileé…ç½®ä¸­è·å–ç ”æŠ¥ç±»å‹
        report_type_str = self.p.get_config().get("report_type", "company")
        
        # ä»æŒ‡ä»¤ä¸­è¯†åˆ«ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        instruction = self.p.get_config().get("instruction", "")
        if instruction:
            return self.report_config.identify_report_type(instruction)
        
        # æ ¹æ®å­—ç¬¦ä¸²æ˜ å°„åˆ°æšä¸¾
        type_mapping = {
            "company": ReportType.COMPANY,
            "industry": ReportType.INDUSTRY, 
            "macro": ReportType.MACRO
        }
        return type_mapping.get(report_type_str.lower(), ReportType.COMPANY)

    #### DATA COLLECTION ACTIONS ####
    def get_competitor_listed_companies(self, context):
        # åªæœ‰å…¬å¸ç ”æŠ¥æ‰éœ€è¦ç«äº‰å¯¹æ‰‹
        if self.current_report_type != ReportType.COMPANY:
            return []
        
        result = identify_competitors_with_ai(
            api_key=self.cfg.api_key,
            base_url=self.cfg.base_url,
            model_name=self.cfg.model,
            company_name=self.p.get_config()['company']
        )
        result = [c for c in result if c.get('market') != "æœªä¸Šå¸‚"]
        return result

    def get_all_financial_data(self, context):
        # åªæœ‰å…¬å¸ç ”æŠ¥æ‰éœ€è¦è´¢åŠ¡æ•°æ®
        if self.current_report_type != ReportType.COMPANY:
            return []
        
        companies = context.get("all_companies", [])
        data_lst = []
        for p in companies:
            try:
                company, code, market = p['company'], p['code'], p['market']
                print(f"è·å–ï¼š{company}({market}:{code})")
                data = get_all_financial_statements(code, market, "å¹´åº¦")
                data_lst.append(data)
                save_financial_statements_to_csv(data, code, market, "å¹´åº¦", company, self.m.data_dir)
                time.sleep(2)
            except Exception as e:
                print(f"âš ï¸ è·å–å¤±è´¥: {e}")
        return data_lst

    def get_all_company_info(self, context):
        # åªæœ‰å…¬å¸ç ”æŠ¥æ‰éœ€è¦å…¬å¸ä¿¡æ¯
        if self.current_report_type != ReportType.COMPANY:
            return ""
        
        def _parse_market( market_str: str, code: str) -> tuple[str, str]:
            """
            è§£æå¸‚åœºä¿¡æ¯å¹¶æ ¼å¼åŒ–è‚¡ç¥¨ä»£ç 
            
            Args:
                market_str (str): å¸‚åœºæè¿°å­—ç¬¦ä¸²ï¼ˆå¦‚"Aè‚¡"ã€"æ¸¯è‚¡"ç­‰ï¼‰
                code (str): åŸå§‹è‚¡ç¥¨ä»£ç 
                
            Returns:
                Tuple[str, str]: è§£æåçš„å¸‚åœºä»£ç å’Œæ ¼å¼åŒ–çš„è‚¡ç¥¨ä»£ç 
                            - Aè‚¡ï¼šè¿”å›("A", "SH000001"æˆ–"SZ000001"æ ¼å¼)
                            - æ¸¯è‚¡ï¼šè¿”å›("HK", åŸä»£ç )
            """
            if "A" in market_str:
                market = "A"
                if not code.startswith("SH") and not code.startswith("SZ"):
                    code = "SH" + code if code.startswith("6") else "SZ" + code
                return market, code
            elif "æ¸¯" in market_str:
                market = "HK"
                return market, code
            return market_str, code

        companies = context.get("all_companies", [])
        for c in companies:
            if 'market' in c and 'code' in c:
                market, code = _parse_market(c['market'], c['code'])
                c['market'] = market
                c['code'] = code
        context["all_companies"] = companies

        result = ""
        for item in companies:
            info = get_stock_intro(item['code'], item['market'])
            if info:
                result += info
                # ä¿å­˜ç®€ä»‹åˆ°txtæ–‡ä»¶
                company = item.get('company', item['code'])
                filecompany = f"{company}_{item['market']}_{item['code']}.txt"
                save_path = os.path.join(self.m.info_dir, filecompany)
                save_stock_intro_to_txt(item['code'], item['market'], save_path)
        return result

    def get_shareholder_analysis(self, context):
        info = get_shareholder_info()
        if info['success']:
            content = get_table_content(info['tables'])
            return self.llm.call("åˆ†æä»¥ä¸‹è‚¡ä¸œä¿¡æ¯ï¼š\n" + content, system_prompt="ä½ æ˜¯è‚¡ä¸œåˆ†æä¸“å®¶")
        return "è‚¡ä¸œä¿¡æ¯è·å–å¤±è´¥"

    def search_industry_info(self, context, engine: str = "sogou"):
        # åªæœ‰å…¬å¸ç ”æŠ¥æ‰éœ€è¦è¡Œä¸šæœç´¢
        if self.current_report_type != ReportType.COMPANY:
            return {}
        
        # å¦‚æœdata/industry_info/all_search_results.jsonå­˜åœ¨ï¼Œåˆ™è¯»å–
        search_results_path = os.path.join(self.m.industry_dir, "all_search_results.json")
        if os.path.exists(search_results_path):
            with open(search_results_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        
        # å¦åˆ™è¿›è¡Œæœç´¢
        companies = [self.p.get_config()['company']] + [c['company'] for c in context.get("all_companies", [])]
        results = {}
        for company in companies:
            r = SearchEngine(engine).search(f"{company} å¸‚åœºä»½é¢ è¡Œä¸šåˆ†æ", max_results=10)
            results[company] = r
            # æ‹¼æ¥æ‰€æœ‰æè¿°
            # all_desc = "\n".join([item['description'] for item in r if 'description' in item])
            # # ç”¨LLMç”Ÿæˆæ‘˜è¦
            # summary = self.llm.call(f"è¯·ç”¨ä¸­æ–‡ç®€è¦æ€»ç»“ä»¥ä¸‹å…³äº{company}çš„è¡Œä¸šå¸‚åœºä»½é¢å’Œç«äº‰åœ°ä½ä¿¡æ¯ï¼š\n{all_desc}", system_prompt="ä½ æ˜¯è¡Œä¸šåˆ†æä¸“å®¶")
            # results[company] = {
            #     "search_results": r,
            #     "summary": summary
            # }
            time.sleep(random.randint(5, 10))

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(self.m.industry_dir, exist_ok=True)
        with open(search_results_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        return results

    #### DATA ANALYSIS ACTIONS ####
    def quick_analysis(self, query, files=None):
        """
        å¿«é€Ÿæ•°æ®åˆ†æå‡½æ•°
        
        Args:
            query: åˆ†æéœ€æ±‚ï¼ˆè‡ªç„¶è¯­è¨€ï¼‰
            files: æ•°æ®æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            output_dir: è¾“å‡ºç›®å½•
            max_rounds: æœ€å¤§åˆ†æè½®æ•°
            
        Returns:
            dict: åˆ†æç»“æœ
        """
        return self.analyzer.analyze(query, files or [])
    
    def get_company_files(self, data_dir):
        """è·å–å…¬å¸æ–‡ä»¶"""
        abs_data_dir = os.path.abspath(data_dir)
        print(f"è·å–å…¬å¸æ•°æ®ç›®å½•: {abs_data_dir}")
        all_files = glob.glob(f"{abs_data_dir}/*.csv")
        companies = {}
        for file in all_files:
            filename = os.path.basename(file)
            company_name = filename.split("_")[0]
            companies.setdefault(company_name, []).append(file)
        return companies

    def analyze_companies_in_directory(self, context):
        """
        åˆ†ææŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰å…¬å¸æ•°æ®
        """
        def analyze_companies(data_directory, query="åŸºäºè¡¨æ ¼çš„æ•°æ®ï¼Œåˆ†ææœ‰ä»·å€¼çš„å†…å®¹ï¼Œå¹¶ç»˜åˆ¶ç›¸å…³å›¾è¡¨ã€‚æœ€åç”Ÿæˆæ±‡æŠ¥ç»™æˆ‘ã€‚"):
            """åˆ†æç›®å½•ä¸­çš„æ‰€æœ‰å…¬å¸"""
            def analyze_individual_company(files, query=None):
                """åˆ†æå•ä¸ªå…¬å¸"""
                if query is None:
                    query = "åŸºäºè¡¨æ ¼çš„æ•°æ®ï¼Œåˆ†ææœ‰ä»·å€¼çš„å†…å®¹ï¼Œå¹¶ç»˜åˆ¶ç›¸å…³å›¾è¡¨ã€‚æœ€åç”Ÿæˆæ±‡æŠ¥ç»™æˆ‘ã€‚"
                report = self.quick_analysis(
                    query=query, files=files
                )
                return report

            company_files = self.get_company_files(data_directory)
            all_reports = {}
            for company_name, files in company_files.items():
                report = analyze_individual_company(files, query)
                if report:
                    all_reports[company_name] = report
            return all_reports

        results = analyze_companies(
            data_directory=self.m.data_dir,
            query="åŸºäºè¡¨æ ¼çš„æ•°æ®ï¼Œåˆ†ææœ‰ä»·å€¼çš„å†…å®¹ï¼Œå¹¶ç»˜åˆ¶ç›¸å…³å›¾è¡¨ã€‚æœ€åç”Ÿæˆæ±‡æŠ¥ç»™æˆ‘ã€‚"
        )

        return results

    def run_comparison_analysis(self, context):
        """
        è¿è¡Œç«äº‰å¯¹æ‰‹åˆ†æ
        """
        # åªæœ‰å…¬å¸ç ”æŠ¥æ‰éœ€è¦å…¬å¸æ¯”è¾ƒ
        if self.current_report_type != ReportType.COMPANY:
            return "éå…¬å¸ç ”æŠ¥ç±»å‹ï¼Œè·³è¿‡å¯¹æ¯”åˆ†æ"
        
        def comparison_analysis(data_directory, target_company_name):
            """è¿è¡Œå¯¹æ¯”åˆ†æ"""
            company_files = self.get_company_files(data_directory)
            if not company_files or target_company_name not in company_files:
                return {}
            competitors = [company for company in company_files.keys() if company != target_company_name]
            comparison_reports = {}
            for competitor in competitors:
                comparison_key = f"{target_company_name}_vs_{competitor}"
                report = compare_two_companies(
                    company_files[target_company_name],
                    company_files[competitor]
                )
                if report:
                    comparison_reports[comparison_key] = {
                        'company1': target_company_name,
                        'company2': competitor,
                        'report': report
                    }
            return comparison_reports

        def compare_two_companies(company1_files, company2_files):
            """æ¯”è¾ƒä¸¤ä¸ªå…¬å¸"""
            query = "åŸºäºä¸¤ä¸ªå…¬å¸çš„è¡¨æ ¼çš„æ•°æ®ï¼Œåˆ†ææœ‰å…±åŒç‚¹çš„éƒ¨åˆ†ï¼Œç»˜åˆ¶å¯¹æ¯”åˆ†æçš„è¡¨æ ¼ï¼Œå¹¶ç»˜åˆ¶ç›¸å…³å›¾è¡¨ã€‚æœ€åç”Ÿæˆæ±‡æŠ¥ç»™æˆ‘ã€‚"
            all_files = company1_files + company2_files
            report = self.quick_analysis(
                query=query,
                files=all_files,
            )
            return report
        
        comparison_results = comparison_analysis(
            data_directory=self.m.data_dir,
            target_company_name=self.p.get_config()['company']
        )

        return comparison_results
    
    def merge_reports(self, context):
        """åˆå¹¶æŠ¥å‘Š"""
        individual_reports = context.get("individual_reports", {})
        comparison_reports = context.get("comparison_reports", {})
        merged = {}
        for company, report in individual_reports.items():
            merged[company] = report
        for comp_key, comp_data in comparison_reports.items():
            merged[comp_key] = comp_data['report']
        return merged
    
    def evaluation(self, context):
        def get_sensetime_files(data_dir):
            """è·å–å•†æ±¤ç§‘æŠ€çš„è´¢åŠ¡æ•°æ®æ–‡ä»¶"""
            abs_data_dir = os.path.abspath(data_dir)
            print(f"è·å–å•†æ±¤ç§‘æŠ€è´¢åŠ¡æ•°æ®ç›®å½•: {abs_data_dir}")
            all_files = glob.glob(f"{abs_data_dir}/*.csv")
            sensetime_files = []
            for file in all_files:
                filename = os.path.basename(file)
                company_name = filename.split("_")[0]
                if "å•†æ±¤" in company_name or "SenseTime" in company_name:
                    sensetime_files.append(file)
            return sensetime_files
        def analyze_sensetime_valuation(files):
            """åˆ†æå•†æ±¤ç§‘æŠ€çš„ä¼°å€¼ä¸é¢„æµ‹"""
            query = "åŸºäºä¸‰å¤§è¡¨çš„æ•°æ®ï¼Œæ„å»ºä¼°å€¼ä¸é¢„æµ‹æ¨¡å‹ï¼Œæ¨¡æ‹Ÿå…³é”®å˜é‡å˜åŒ–å¯¹è´¢åŠ¡ç»“æœçš„å½±å“,å¹¶ç»˜åˆ¶ç›¸å…³å›¾è¡¨ã€‚æœ€åç”Ÿæˆæ±‡æŠ¥ç»™æˆ‘ã€‚"
            report = self.quick_analysis(query=query, files=files)
            return report

        # å•†æ±¤ç§‘æŠ€ä¼°å€¼ä¸é¢„æµ‹åˆ†æ
        sensetime_files = get_sensetime_files(self.m.data_dir)
        sensetime_valuation_report = None
        if sensetime_files:
            sensetime_valuation_report = analyze_sensetime_valuation(sensetime_files)
        return sensetime_valuation_report if sensetime_valuation_report else "å•†æ±¤ç§‘æŠ€çš„ä¼°å€¼ä¸é¢„æµ‹åˆ†ææœªèƒ½å®Œæˆæˆ–æ— ç›¸å…³æ•°æ®ã€‚"
    
    def get_analysis_report(self, context):
        """
        è·å–åˆ†ææŠ¥å‘Š
        """
        def get_company_infos(data_dir="./data/info"):
            """è·å–å…¬å¸ä¿¡æ¯"""
            abs_data_dir = os.path.abspath(data_dir)
            print(f"è·å–å…¬å¸ä¿¡æ¯ç›®å½•: {abs_data_dir}")
            all_files = os.listdir(abs_data_dir)
            company_infos = ""
            for file in all_files:
                if file.endswith(".txt"):
                    company_name = file.split(".")[0]
                    with open(os.path.join(data_dir, file), 'r', encoding='utf-8') as f:
                        content = f.read()
                    company_infos += f"ã€å…¬å¸ä¿¡æ¯å¼€å§‹ã€‘\nå…¬å¸åç§°: {company_name}\n{content}\nã€å…¬å¸ä¿¡æ¯ç»“æŸã€‘\n\n"
            return company_infos
        
        def format_final_reports(all_reports):
            """æ ¼å¼åŒ–æœ€ç»ˆæŠ¥å‘Š"""
            formatted_output = []
            for company_name, report in all_reports.items():
                formatted_output.append(f"ã€{company_name}è´¢åŠ¡æ•°æ®åˆ†æç»“æœå¼€å§‹ã€‘")
                final_report = report.get("final_report", "æœªç”ŸæˆæŠ¥å‘Š")
                formatted_output.append(final_report)
                formatted_output.append(f"ã€{company_name}è´¢åŠ¡æ•°æ®åˆ†æç»“æœç»“æŸã€‘")
                formatted_output.append("")
            return "\n".join(formatted_output)
        
        # æ•´ç†å…¬å¸ä¿¡æ¯
        company_infos = get_company_infos()
        company_infos = self.llm.call(
            f"è¯·æ•´ç†ä»¥ä¸‹å…¬å¸ä¿¡æ¯å†…å®¹ï¼Œç¡®ä¿æ ¼å¼æ¸…æ™°æ˜“è¯»ï¼Œå¹¶ä¿ç•™å…³é”®ä¿¡æ¯ï¼š\n{company_infos}",
            system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å…¬å¸ä¿¡æ¯æ•´ç†å¸ˆã€‚",
            max_tokens=8192,
            temperature=0.5
        )
        
        # æ•´ç†è‚¡æƒä¿¡æ¯
        info = get_shareholder_info()
        shangtang_shareholder_info = info.get("tables", [])
        table_content = get_table_content(shangtang_shareholder_info)
        shareholder_analysis = self.llm.call(
            "è¯·åˆ†æä»¥ä¸‹è‚¡ä¸œä¿¡æ¯è¡¨æ ¼å†…å®¹ï¼š\n" + table_content,
            system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è‚¡ä¸œä¿¡æ¯åˆ†æå¸ˆã€‚",
            max_tokens=8192,
            temperature=0.5
        )
        
        # æ•´ç†è¡Œä¸šä¿¡æ¯æœç´¢ç»“æœ
        search_results_file = os.path.join(self.m.industry_dir, "all_search_results.json")
        with open(search_results_file, 'r', encoding='utf-8') as f:
            all_search_results = json.load(f)
        search_res = ""
        for company, results in all_search_results.items():
            search_res += f"ã€{company}æœç´¢ä¿¡æ¯å¼€å§‹ã€‘\n"
            for result in results:
                search_res += f"æ ‡é¢˜: {result.get('title', 'æ— æ ‡é¢˜')}\n"
                search_res += f"é“¾æ¥: {result.get('href', 'æ— é“¾æ¥')}\n"
                search_res += f"æ‘˜è¦: {result.get('body', 'æ— æ‘˜è¦')}\n"
                search_res += "----\n"
            search_res += f"ã€{company}æœç´¢ä¿¡æ¯ç»“æŸã€‘\n\n"
        
        # ä¿å­˜é˜¶æ®µä¸€ç»“æœ
        merged_results = context.get("merged_results", {})
        sensetime_valuation_report = context.get("sensetime_valuation_report", None)
        formatted_report = format_final_reports(merged_results)
        
        # ğŸ” æŸ¥æ‰¾å¹¶æ·»åŠ sessionç›®å½•ä¸­çš„å›¾è¡¨
        charts_section = self._find_and_add_session_charts()
        
        # ç»Ÿä¸€ä¿å­˜ä¸ºmarkdown
        md_output_file = f"è´¢åŠ¡ç ”æŠ¥æ±‡æ€»_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        with open(md_output_file, 'w', encoding='utf-8') as f:
            f.write(f"# å…¬å¸åŸºç¡€ä¿¡æ¯\n\n## æ•´ç†åå…¬å¸ä¿¡æ¯\n\n{company_infos}\n\n")
            f.write(f"# è‚¡æƒä¿¡æ¯åˆ†æ\n\n{shareholder_analysis}\n\n")
            f.write(f"# è¡Œä¸šä¿¡æ¯æœç´¢ç»“æœ\n\n{search_res}\n\n")
            f.write(f"# è´¢åŠ¡æ•°æ®åˆ†æä¸ä¸¤ä¸¤å¯¹æ¯”\n\n{formatted_report}\n\n")
            if sensetime_valuation_report and isinstance(sensetime_valuation_report, dict):
                f.write(f"# å•†æ±¤ç§‘æŠ€ä¼°å€¼ä¸é¢„æµ‹åˆ†æ\n\n{sensetime_valuation_report.get('final_report', 'æœªç”ŸæˆæŠ¥å‘Š')}\n\n")
            # æ·»åŠ å›¾è¡¨éƒ¨åˆ†
            if charts_section:
                f.write(charts_section)
        
        print(f"\nâœ… ç¬¬ä¸€é˜¶æ®µå®Œæˆï¼åŸºç¡€åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {md_output_file}")
        
        # ğŸ¯ ä¿å­˜æŠ¥å‘Šè·¯å¾„åˆ°ç±»å±æ€§
        self._update_report_path("analysis_report", md_output_file)
        
        # å­˜å‚¨ç»“æœä¾›ç¬¬äºŒé˜¶æ®µä½¿ç”¨
        self.analysis_results = {
            'md_file': md_output_file,
            'company_infos': company_infos,
            'shareholder_analysis': shareholder_analysis,
            'search_res': search_res,
            'formatted_report': formatted_report,
            'sensetime_valuation_report': sensetime_valuation_report
        }
        return md_output_file
    
    def _find_and_add_session_charts(self):
        """æŸ¥æ‰¾sessionç›®å½•ä¸­çš„å›¾è¡¨å¹¶ç”Ÿæˆmarkdownå¼•ç”¨"""
        import glob
        
        print("ğŸ” æœç´¢sessionç›®å½•ä¸­çš„åˆ†æå›¾è¡¨...")
        data_financials_dir = os.path.join(os.getcwd(), "data", "financials")
        
        if not os.path.exists(data_financials_dir):
            print("âš ï¸ æœªæ‰¾åˆ°data/financialsç›®å½•")
            return ""
        
        # æ‰¾åˆ°æ‰€æœ‰sessionç›®å½•
        session_dirs = [d for d in os.listdir(data_financials_dir) if d.startswith('session_')]
        if not session_dirs:
            print("âš ï¸ æœªæ‰¾åˆ°sessionç›®å½•")
            return ""
        
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œé€‰æ‹©æœ€æ–°çš„session
        session_dirs.sort(key=lambda x: os.path.getmtime(os.path.join(data_financials_dir, x)), reverse=True)
        latest_session = session_dirs[0]
        session_path = os.path.join(data_financials_dir, latest_session)
        
        print(f"ğŸ“Š ä½¿ç”¨æœ€æ–°sessionç›®å½•: {latest_session}")
        
        # æŸ¥æ‰¾æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
        image_files = []
        for ext in ['*.png', '*.jpg', '*.jpeg', '*.gif', '*.svg']:
            image_files.extend(glob.glob(os.path.join(session_path, ext)))
        
        if not image_files:
            print("âš ï¸ sessionç›®å½•ä¸­æœªå‘ç°å›¾è¡¨æ–‡ä»¶")
            return ""
        
        print(f"ğŸ“ˆ å‘ç° {len(image_files)} ä¸ªåˆ†æå›¾è¡¨")
        
        # ç”Ÿæˆå›¾è¡¨å±•ç¤ºéƒ¨åˆ†
        charts_section = "\n\n# è´¢åŠ¡åˆ†æå›¾è¡¨\n\n"
        charts_section += "ä»¥ä¸‹æ˜¯ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆçš„è´¢åŠ¡åˆ†æå›¾è¡¨ï¼š\n\n"
        
        for img_file in image_files:
            filename = os.path.basename(img_file)
            # ä½¿ç”¨ç›¸å¯¹è·¯å¾„å¼•ç”¨ï¼Œæ–¹ä¾¿åç»­å¤„ç†
            relative_path = f"./data/financials/{latest_session}/{filename}"
            
            # ç”Ÿæˆæ›´å‹å¥½çš„å›¾è¡¨åç§°
            chart_name = filename.replace('_', ' ').replace('-', ' ').replace('.png', '').replace('.jpg', '').replace('.jpeg', '').title()
            
            charts_section += f"## {chart_name}\n\n"
            charts_section += f"![{chart_name}]({relative_path})\n\n"
            print(f"âœ… å·²æ·»åŠ å›¾è¡¨å¼•ç”¨: {chart_name}")
        
        return charts_section
    


    #### REPORT GENERATION ACTIONS ####
    def deep_report_generation(self, context):
        """ç¬¬äºŒé˜¶æ®µï¼šæ·±åº¦ç ”æŠ¥ç”Ÿæˆ"""
        print("\n" + "="*80)
        print("ğŸš€ å¼€å§‹ç¬¬äºŒé˜¶æ®µï¼šæ·±åº¦ç ”æŠ¥ç”Ÿæˆ")
        print("="*80)
        
        # å¤„ç†å›¾ç‰‡è·¯å¾„
        print("ğŸ–¼ï¸ å¤„ç†å›¾ç‰‡è·¯å¾„...")
        md_file_path = context.get("get_analysis_report", self.default_report_path)
        new_md_path = md_file_path.replace('.md', '_images.md')
        images_dir = os.path.join(os.path.dirname(md_file_path), 'images')
        extract_images_from_markdown(md_file_path, images_dir, new_md_path)
        
        # åŠ è½½æŠ¥å‘Šå†…å®¹
        report_content = load_report_content(new_md_path)
        background = get_background()
        
        # ç”Ÿæˆå¤§çº²
        print("\nğŸ“‹ ç”ŸæˆæŠ¥å‘Šå¤§çº²...")
        parts = generate_outline(self.llm, background, report_content)
        
        # åˆ†æ®µç”Ÿæˆæ·±åº¦ç ”æŠ¥
        print("\nâœï¸ å¼€å§‹åˆ†æ®µç”Ÿæˆæ·±åº¦ç ”æŠ¥...")
        full_report = ['# å•†æ±¤ç§‘æŠ€å…¬å¸ç ”æŠ¥\n']
        prev_content = ''
        
        for idx, part in enumerate(parts):
            part_title = part.get('part_title', f'éƒ¨åˆ†{idx+1}')
            print(f"\n  æ­£åœ¨ç”Ÿæˆï¼š{part_title}")
            is_last = (idx == len(parts) - 1)
            section_text = generate_section(
                self.llm, part_title, prev_content, background, report_content, is_last
            )
            full_report.append(section_text)
            print(f"  âœ… å·²å®Œæˆï¼š{part_title}")
            prev_content = '\n'.join(full_report)
        
        # ä¿å­˜æœ€ç»ˆæŠ¥å‘Š
        final_report = '\n\n'.join(full_report)
        output_file = f"æ·±åº¦è´¢åŠ¡ç ”æŠ¥åˆ†æ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        save_markdown(final_report, output_file)
        
        # ğŸ¯ ä¿å­˜æŠ¥å‘Šè·¯å¾„åˆ°ç±»å±æ€§
        self._update_report_path("deep_report", output_file)
        self._update_report_path("company_report", output_file)  # å…¬å¸ç ”æŠ¥ä¹ŸæŒ‡å‘æ·±åº¦æŠ¥å‘Š
        
        # æ ¼å¼åŒ–å’Œè½¬æ¢
        print("\nğŸ¨ æ ¼å¼åŒ–æŠ¥å‘Š...")
        format_markdown(output_file)
        
        print("\nğŸ“„ è½¬æ¢ä¸ºWordæ–‡æ¡£...")
        convert_to_docx(output_file)
        
        return {"deep_report_file": output_file, "status": "completed"}

    #### è¡Œä¸šç ”æŠ¥æ•°æ®æ”¶é›†å·¥å…· ####
    def get_industry_overview(self, context):
        """è·å–è¡Œä¸šæ¦‚å†µ"""
        industry_name = self.p.get_config().get("industry", "äººå·¥æ™ºèƒ½")
        print(f"ğŸ” æ”¶é›†è¡Œä¸šæ¦‚å†µï¼š{industry_name}")
        return self.industry_collector.get_industry_overview(industry_name)
    
    def get_industry_chain_analysis(self, context):
        """è·å–äº§ä¸šé“¾åˆ†æ"""
        industry_name = self.p.get_config().get("industry", "äººå·¥æ™ºèƒ½")
        print(f"ğŸ”— åˆ†æäº§ä¸šé“¾ï¼š{industry_name}")
        return self.industry_collector.get_industry_chain_analysis(industry_name)
    
    def get_industry_policy_impact(self, context):
        """è·å–è¡Œä¸šæ”¿ç­–å½±å“"""
        industry_name = self.p.get_config().get("industry", "äººå·¥æ™ºèƒ½")
        print(f"ğŸ“œ æ”¶é›†æ”¿ç­–å½±å“ï¼š{industry_name}")
        return self.industry_collector.get_industry_policy_impact(industry_name)
    
    def get_industry_technology_trends(self, context):
        """è·å–è¡Œä¸šæŠ€æœ¯å‘å±•è¶‹åŠ¿"""
        industry_name = self.p.get_config().get("industry", "äººå·¥æ™ºèƒ½")
        print(f"ğŸš€ åˆ†ææŠ€æœ¯è¶‹åŠ¿ï¼š{industry_name}")
        return self.industry_collector.get_industry_technology_trends(industry_name)
    
    def get_industry_association_reports(self, context):
        """è·å–è¡Œä¸šåä¼šæŠ¥å‘Š"""
        industry_name = self.p.get_config().get("industry", "äººå·¥æ™ºèƒ½")
        print(f"ğŸ“Š æ”¶é›†åä¼šæŠ¥å‘Šï¼š{industry_name}")
        return self.industry_collector.get_industry_association_reports(industry_name)
    
    def get_industry_market_scale(self, context):
        """è·å–è¡Œä¸šå¸‚åœºè§„æ¨¡"""
        industry_name = self.p.get_config().get("industry", "äººå·¥æ™ºèƒ½")
        print(f"ğŸ“ˆ åˆ†æå¸‚åœºè§„æ¨¡ï¼š{industry_name}")
        return self.industry_collector.get_industry_market_scale(industry_name)
    
    def get_leading_companies_data(self, context):
        """è·å–è¡Œä¸šé¾™å¤´ä¼ä¸šæ•°æ®"""
        industry_name = self.p.get_config().get("industry", "äººå·¥æ™ºèƒ½")
        print(f"ğŸ¢ æ”¶é›†é¾™å¤´ä¼ä¸šæ•°æ®ï¼š{industry_name}")
        
        # æœç´¢è¡Œä¸šé¾™å¤´ä¼ä¸š
        search_engine = SearchEngine("sogou")
        search_query = f"{industry_name} é¾™å¤´ä¼ä¸š ä¸Šå¸‚å…¬å¸ æ’å"
        search_results = list(search_engine.search(search_query, max_results=10))

        # ä¿å­˜æœç´¢ç»“æœ
        filename = f"{industry_name}_leading_companies.json"
        filepath = os.path.join(self.m.industry_dir, filename)
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(search_results, f, ensure_ascii=False, indent=2)
        
        return search_results

    #### å®è§‚ç»æµæ•°æ®æ”¶é›†å·¥å…· ####
    def get_gdp_data(self, context):
        """è·å–GDPæ•°æ®"""
        country = self.p.get_config().get("country", "ä¸­å›½")
        print(f"ğŸ“Š æ”¶é›†GDPæ•°æ®ï¼š{country}")
        return self.macro_collector.get_gdp_data(country)
    
    def get_cpi_data(self, context):
        """è·å–CPIæ•°æ®"""
        country = self.p.get_config().get("country", "ä¸­å›½")
        print(f"ğŸ’° æ”¶é›†CPIæ•°æ®ï¼š{country}")
        return self.macro_collector.get_cpi_data(country)
    
    def get_interest_rate_data(self, context):
        """è·å–åˆ©ç‡æ•°æ®"""
        country = self.p.get_config().get("country", "ä¸­å›½")
        print(f"ğŸ“ˆ æ”¶é›†åˆ©ç‡æ•°æ®ï¼š{country}")
        return self.macro_collector.get_interest_rate_data(country)
    
    def get_exchange_rate_data(self, context):
        """è·å–æ±‡ç‡æ•°æ®"""
        base_currency = self.p.get_config().get("base_currency", "äººæ°‘å¸")
        target_currency = self.p.get_config().get("target_currency", "ç¾å…ƒ")
        print(f"ğŸ’± æ”¶é›†æ±‡ç‡æ•°æ®ï¼š{base_currency}-{target_currency}")
        return self.macro_collector.get_exchange_rate_data(base_currency, target_currency)
    
    def get_federal_reserve_data(self, context):
        """è·å–ç¾è”å‚¨æ•°æ®"""
        print("ğŸ¦ æ”¶é›†ç¾è”å‚¨åˆ©ç‡æ•°æ®")
        return self.macro_collector.get_federal_reserve_data()
    
    def get_policy_reports(self, context):
        """è·å–æ”¿ç­–æŠ¥å‘Š"""
        country = self.p.get_config().get("country", "ä¸­å›½")
        print(f"ğŸ“œ æ”¶é›†æ”¿ç­–æŠ¥å‘Šï¼š{country}")
        return self.macro_collector.get_policy_reports(country)
    
    def get_macro_industry_impact(self, context):
        """è·å–å®è§‚å¯¹è¡Œä¸šçš„å½±å“"""
        industry_name = self.p.get_config().get("industry", "ç§‘æŠ€è¡Œä¸š")
        print(f"ğŸŒ åˆ†æå®è§‚å¯¹è¡Œä¸šå½±å“ï¼š{industry_name}")
        return self.macro_collector.get_industry_policy_impact(industry_name)

    def _gather_industry_data(self, context, industry_name):
        """æ•´åˆä¹‹å‰æ”¶é›†çš„è¡Œä¸šæ•°æ®"""
        collected_data = {}
        
        # ä»contextä¸­è·å–æ•°æ®
        overview_data = context.get("get_industry_overview", {})
        chain_data = context.get("get_industry_chain_analysis", {})
        leading_companies_data = context.get("get_leading_companies_data", [])
        market_scale_data = context.get("get_industry_market_scale", {})
        policy_data = context.get("get_industry_policy_impact", {})
        tech_trends_data = context.get("get_industry_technology_trends", {})
        association_data = context.get("get_industry_association_reports", {})
        
        # ä»æ–‡ä»¶ä¸­åŠ è½½æ•°æ®ï¼ˆå¦‚æœcontextä¸­æ²¡æœ‰ï¼‰
        if not overview_data:
            overview_file = os.path.join(self.m.industry_dir, f"{industry_name}_overview.json")
            if os.path.exists(overview_file):
                with open(overview_file, 'r', encoding='utf-8') as f:
                    overview_data = json.load(f)
        
        if not chain_data:
            chain_file = os.path.join(self.m.industry_dir, f"{industry_name}_chain_analysis.json")
            if os.path.exists(chain_file):
                with open(chain_file, 'r', encoding='utf-8') as f:
                    chain_data = json.load(f)
        
        if not leading_companies_data:
            companies_file = os.path.join(self.m.industry_dir, f"{industry_name}_leading_companies.json")
            if os.path.exists(companies_file):
                with open(companies_file, 'r', encoding='utf-8') as f:
                    leading_companies_data = json.load(f)
        
        if not market_scale_data:
            market_file = os.path.join(self.m.industry_dir, f"{industry_name}_market_scale.json")
            if os.path.exists(market_file):
                with open(market_file, 'r', encoding='utf-8') as f:
                    market_scale_data = json.load(f)
        
        # æ•´ç†æ•°æ®
        if overview_data:
            collected_data['overview'] = self._format_search_results(overview_data, "è¡Œä¸šæ¦‚å†µ")
        
        if chain_data:
            collected_data['chain_analysis'] = self._format_search_results(chain_data, "äº§ä¸šé“¾åˆ†æ")
        
        if leading_companies_data:
            collected_data['leading_companies'] = self._format_search_results_list(leading_companies_data, "é¾™å¤´ä¼ä¸š")
        
        if market_scale_data:
            collected_data['market_scale'] = self._format_search_results(market_scale_data, "å¸‚åœºè§„æ¨¡")
        
        if policy_data:
            collected_data['policy_impact'] = self._format_search_results(policy_data, "æ”¿ç­–å½±å“")
        
        if tech_trends_data:
            collected_data['tech_trends'] = self._format_search_results(tech_trends_data, "æŠ€æœ¯è¶‹åŠ¿")
            
        if association_data:
            collected_data['association_reports'] = self._format_search_results(association_data, "åä¼šæŠ¥å‘Š")
        
        return collected_data
    
    def _format_search_results(self, data, data_type):
        """æ ¼å¼åŒ–æœç´¢ç»“æœæ•°æ®"""
        if not data:
            return f"æš‚æ— {data_type}æ•°æ®"
        
        formatted_text = f"\n=== {data_type} ===\n"
        
        for query, results in data.items():
            formatted_text += f"\nã€{query}ã€‘\n"
            for i, result in enumerate(results[:3], 1):  # åªå–å‰3ä¸ªç»“æœ
                title = result.get('title', 'æ— æ ‡é¢˜')
                description = result.get('description', result.get('body', 'æ— æè¿°'))
                url = result.get('url', result.get('href', ''))
                
                formatted_text += f"{i}. {title}\n"
                if description:
                    # æˆªå–æè¿°çš„å‰200å­—ç¬¦
                    desc_short = description[:200] + "..." if len(description) > 200 else description
                    formatted_text += f"   æ‘˜è¦: {desc_short}\n"
                if url:
                    formatted_text += f"   é“¾æ¥: {url}\n"
                formatted_text += "\n"
        
        return formatted_text
    
    def _format_search_results_list(self, data_list, data_type):
        """æ ¼å¼åŒ–æœç´¢ç»“æœåˆ—è¡¨"""
        if not data_list:
            return f"æš‚æ— {data_type}æ•°æ®"
        
        formatted_text = f"\n=== {data_type} ===\n"
        
        for i, result in enumerate(data_list[:5], 1):  # åªå–å‰5ä¸ªç»“æœ
            title = result.get('title', 'æ— æ ‡é¢˜')
            description = result.get('description', result.get('body', 'æ— æè¿°'))
            url = result.get('url', result.get('href', ''))
            
            formatted_text += f"{i}. {title}\n"
            if description:
                desc_short = description[:200] + "..." if len(description) > 200 else description
                formatted_text += f"   æ‘˜è¦: {desc_short}\n"
            if url:
                formatted_text += f"   é“¾æ¥: {url}\n"
            formatted_text += "\n"
        
        return formatted_text

    #### åˆ†æå·¥å…·æ‰©å±• ####
    def analyze_industry_structure(self, context):
        """åˆ†æè¡Œä¸šç»“æ„"""
        print("ğŸ—ï¸ åˆ†æè¡Œä¸šç»“æ„")
        industry_name = self.p.get_config().get("industry", "äººå·¥æ™ºèƒ½")
        
        # æ•´åˆä¹‹å‰æ”¶é›†çš„æ•°æ®
        collected_data = self._gather_industry_data(context, industry_name)
        
        if not collected_data:
            raise ValueError("ç¼ºå°‘è¡Œä¸šæ•°æ®ï¼Œè¯·å…ˆæ‰§è¡Œæ•°æ®æ”¶é›†æ­¥éª¤")
        
        # æ„å»ºåŒ…å«å®é™…æ•°æ®çš„åˆ†æprompt
        analysis_prompt = f"""
        åŸºäºä»¥ä¸‹æ”¶é›†åˆ°çš„{industry_name}è¡Œä¸šå®é™…æ•°æ®ï¼Œè¯·è¿›è¡Œæ·±å…¥çš„è¡Œä¸šç»“æ„åˆ†æï¼š

        === è¡Œä¸šæ¦‚å†µæ•°æ® ===
        {collected_data.get('overview', 'æš‚æ— æ•°æ®')}

        === äº§ä¸šé“¾æ•°æ® ===
        {collected_data.get('chain_analysis', 'æš‚æ— æ•°æ®')}

        === é¾™å¤´ä¼ä¸šæ•°æ® ===
        {collected_data.get('leading_companies', 'æš‚æ— æ•°æ®')}

        === å¸‚åœºè§„æ¨¡æ•°æ® ===
        {collected_data.get('market_scale', 'æš‚æ— æ•°æ®')}

        è¯·åŸºäºä»¥ä¸ŠçœŸå®æ•°æ®åˆ†æï¼š
        1. è¡Œä¸šå‘å±•é˜¶æ®µå’Œæˆç†Ÿåº¦ï¼ˆå¼•ç”¨å…·ä½“æ•°æ®æ”¯æ’‘ï¼‰
        2. å¸‚åœºé›†ä¸­åº¦å’Œç«äº‰æ ¼å±€ï¼ˆåŸºäºé¾™å¤´ä¼ä¸šå’Œå¸‚åœºæ•°æ®ï¼‰
        3. äº§ä¸šé“¾åˆ†å·¥å’Œä»·å€¼åˆ†å¸ƒï¼ˆåŸºäºäº§ä¸šé“¾æ•°æ®ï¼‰
        4. ä¸»è¦å‚ä¸è€…å’Œå•†ä¸šæ¨¡å¼ï¼ˆåŸºäºä¼ä¸šæ•°æ®ï¼‰
        
        è¯·ç¡®ä¿åˆ†æç»“è®ºæœ‰æ•°æ®æ”¯æ’‘ï¼Œé¿å…ç©ºæ³›æè¿°ã€‚
        """
        
        return self.llm.call(analysis_prompt, system_prompt="ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è¡Œä¸šåˆ†æå¸ˆï¼Œè¯·åŸºäºæä¾›çš„çœŸå®æ•°æ®è¿›è¡Œåˆ†æ")
    
    def analyze_industry_trends(self, context):
        """åˆ†æè¡Œä¸šå‘å±•è¶‹åŠ¿"""
        print("ğŸ“ˆ åˆ†æè¡Œä¸šå‘å±•è¶‹åŠ¿")
        industry_name = self.p.get_config().get("industry", "äººå·¥æ™ºèƒ½")
        
        # æ•´åˆä¹‹å‰æ”¶é›†çš„æ•°æ®
        collected_data = self._gather_industry_data(context, industry_name)
        
        if not collected_data:
            return "ç¼ºå°‘è¡Œä¸šæ•°æ®ï¼Œè¯·å…ˆæ‰§è¡Œæ•°æ®æ”¶é›†æ­¥éª¤"
        
        # æ„å»ºåŒ…å«å®é™…æ•°æ®çš„åˆ†æprompt
        analysis_prompt = f"""
        åŸºäºä»¥ä¸‹æ”¶é›†åˆ°çš„{industry_name}è¡Œä¸šå®é™…æ•°æ®ï¼Œè¯·è¿›è¡Œæ·±å…¥çš„è¡Œä¸šå‘å±•è¶‹åŠ¿åˆ†æï¼š

        === æŠ€æœ¯è¶‹åŠ¿æ•°æ® ===
        {collected_data.get('tech_trends', 'æš‚æ— æ•°æ®')}

        === å¸‚åœºè§„æ¨¡æ•°æ® ===
        {collected_data.get('market_scale', 'æš‚æ— æ•°æ®')}

        === æ”¿ç­–å½±å“æ•°æ® ===
        {collected_data.get('policy_impact', 'æš‚æ— æ•°æ®')}

        === åä¼šæŠ¥å‘Šæ•°æ® ===
        {collected_data.get('association_reports', 'æš‚æ— æ•°æ®')}

        è¯·åŸºäºä»¥ä¸ŠçœŸå®æ•°æ®åˆ†æï¼š
        1. æŠ€æœ¯å‘å±•è¶‹åŠ¿å’Œåˆ›æ–°æ–¹å‘ï¼ˆå¼•ç”¨å…·ä½“æŠ€æœ¯æ•°æ®ï¼‰
        2. å¸‚åœºè§„æ¨¡å¢é•¿é¢„æµ‹ï¼ˆåŸºäºçœŸå®å¸‚åœºæ•°æ®ï¼‰
        3. æ”¿ç­–ç¯å¢ƒå˜åŒ–å½±å“ï¼ˆåŸºäºæ”¿ç­–æ•°æ®åˆ†æï¼‰
        4. æœªæ¥3-5å¹´å‘å±•å‰æ™¯ï¼ˆç»¼åˆå„é¡¹æ•°æ®é¢„æµ‹ï¼‰
        
        è¯·ç¡®ä¿åˆ†æç»“è®ºæœ‰æ•°æ®æ”¯æ’‘ï¼Œé¿å…ç©ºæ³›æè¿°ã€‚
        """
        
        return self.llm.call(analysis_prompt, system_prompt="ä½ æ˜¯ä¸€ä½èµ„æ·±çš„è¡Œä¸šç ”ç©¶ä¸“å®¶ï¼Œè¯·åŸºäºæä¾›çš„çœŸå®æ•°æ®è¿›è¡Œåˆ†æ")
    
    def _gather_macro_data(self, context, country="ä¸­å›½"):
        """æ•´åˆä¹‹å‰æ”¶é›†çš„å®è§‚ç»æµæ•°æ®"""
        collected_data = {}
        
        # ä»contextä¸­è·å–æ•°æ®
        gdp_data = context.get("get_gdp_data", {})
        cpi_data = context.get("get_cpi_data", {})
        interest_rate_data = context.get("get_interest_rate_data", {})
        exchange_rate_data = context.get("get_exchange_rate_data", {})
        fed_data = context.get("get_federal_reserve_data", {})
        policy_data = context.get("get_policy_reports", {})
        industry_impact_data = context.get("get_macro_industry_impact", {})
        
        # ä»æ–‡ä»¶ä¸­åŠ è½½æ•°æ®ï¼ˆå¦‚æœcontextä¸­æ²¡æœ‰ï¼‰
        if not gdp_data:
            gdp_file = os.path.join("./data", "macro", f"{country}_gdp_data.json")
            if os.path.exists(gdp_file):
                with open(gdp_file, 'r', encoding='utf-8') as f:
                    gdp_data = json.load(f)
        
        if not cpi_data:
            cpi_file = os.path.join("./data", "macro", f"{country}_cpi_data.json")
            if os.path.exists(cpi_file):
                with open(cpi_file, 'r', encoding='utf-8') as f:
                    cpi_data = json.load(f)

        if not interest_rate_data:
            interest_rate_file = os.path.join("./data", "macro", f"{country}_interest_rate_data.json")
            if os.path.exists(interest_rate_file):
                with open(interest_rate_file, 'r', encoding='utf-8') as f:
                    interest_rate_data = json.load(f)
        
        if not exchange_rate_data:
            exchange_rate_file = os.path.join("./data", "macro", f"exchange_rate.json")
            if os.path.exists(exchange_rate_file):
                with open(exchange_rate_file, 'r', encoding='utf-8') as f:
                    exchange_rate_data = json.load(f)

        if not fed_data:
            fed_rate_file = os.path.join("./data", "macro", "fed_interest_rate_data.json")
            if os.path.exists(fed_rate_file):
                with open(fed_rate_file, 'r', encoding='utf-8') as f:
                    fed_data = json.load(f)

        if not policy_data:
            policy_file = os.path.join("./data", "macro", f"{country}_policy_reports.json")
            if os.path.exists(policy_file):
                with open(policy_file, 'r', encoding='utf-8') as f:
                    policy_data = json.load(f)
        
        if not industry_impact_data:
            industry_impact_file = os.path.join("./data", "macro", "policy_impact.json")
            if os.path.exists(industry_impact_file):
                with open(industry_impact_file, 'r', encoding='utf-8') as f:
                    industry_impact_data = json.load(f)

        # æ•´ç†æ•°æ®
        if gdp_data:
            collected_data['gdp'] = self._format_search_results(gdp_data, "GDPæ•°æ®")
        
        if cpi_data:
            collected_data['cpi'] = self._format_search_results(cpi_data, "CPIæ•°æ®")
        
        if interest_rate_data:
            collected_data['interest_rate'] = self._format_search_results(interest_rate_data, "åˆ©ç‡æ•°æ®")
        
        if exchange_rate_data:
            collected_data['exchange_rate'] = self._format_search_results(exchange_rate_data, "æ±‡ç‡æ•°æ®")
        
        if fed_data:
            collected_data['federal_reserve'] = self._format_search_results(fed_data, "ç¾è”å‚¨æ•°æ®")
        
        if policy_data:
            collected_data['policy'] = self._format_search_results(policy_data, "æ”¿ç­–æŠ¥å‘Š")
        
        if industry_impact_data:
            collected_data['industry_impact'] = self._format_search_results(industry_impact_data, "è¡Œä¸šå½±å“")
        
        return collected_data

    def analyze_macro_trends(self, context):
        """åˆ†æå®è§‚ç»æµè¶‹åŠ¿"""
        print("ğŸŒ åˆ†æå®è§‚ç»æµè¶‹åŠ¿")
        country = self.p.get_config().get("country", "ä¸­å›½")
        
        # æ•´åˆä¹‹å‰æ”¶é›†çš„æ•°æ®
        collected_data = self._gather_macro_data(context, country)
        
        if not collected_data:
            return "ç¼ºå°‘å®è§‚ç»æµæ•°æ®ï¼Œè¯·å…ˆæ‰§è¡Œæ•°æ®æ”¶é›†æ­¥éª¤"
        
        # æ„å»ºåŒ…å«å®é™…æ•°æ®çš„åˆ†æprompt
        analysis_prompt = f"""
        åŸºäºä»¥ä¸‹æ”¶é›†åˆ°çš„{country}å®è§‚ç»æµå®é™…æ•°æ®ï¼Œè¯·è¿›è¡Œæ·±å…¥çš„å®è§‚ç»æµè¶‹åŠ¿åˆ†æï¼š

        === GDPæ•°æ® ===
        {collected_data.get('gdp', 'æš‚æ— æ•°æ®')}

        === CPIé€šèƒ€æ•°æ® ===
        {collected_data.get('cpi', 'æš‚æ— æ•°æ®')}

        === åˆ©ç‡æ•°æ® ===
        {collected_data.get('interest_rate', 'æš‚æ— æ•°æ®')}

        === æ±‡ç‡æ•°æ® ===
        {collected_data.get('exchange_rate', 'æš‚æ— æ•°æ®')}

        === ç¾è”å‚¨æ”¿ç­–æ•°æ® ===
        {collected_data.get('federal_reserve', 'æš‚æ— æ•°æ®')}

        === æ”¿ç­–æŠ¥å‘Šæ•°æ® ===
        {collected_data.get('policy', 'æš‚æ— æ•°æ®')}

        è¯·åŸºäºä»¥ä¸ŠçœŸå®æ•°æ®åˆ†æï¼š
        1. GDPå¢é•¿åŠ¨åŠ›å’Œç»“æ„å˜åŒ–ï¼ˆå¼•ç”¨å…·ä½“GDPæ•°æ®ï¼‰
        2. é€šèƒ€å‹åŠ›å’Œè´§å¸æ”¿ç­–èµ°å‘ï¼ˆåŸºäºCPIå’Œåˆ©ç‡æ•°æ®ï¼‰
        3. æ±‡ç‡ç¯å¢ƒå¯¹ç»æµçš„å½±å“ï¼ˆåŸºäºæ±‡ç‡æ•°æ®åˆ†æï¼‰
        4. å›½é™…ç¯å¢ƒå¯¹å›½å†…ç»æµçš„å½±å“ï¼ˆç»“åˆç¾è”å‚¨æ”¿ç­–æ•°æ®ï¼‰
        
        è¯·ç¡®ä¿åˆ†æç»“è®ºæœ‰æ•°æ®æ”¯æ’‘ï¼Œé¿å…ç©ºæ³›æè¿°ã€‚
        """
        
        return self.llm.call(analysis_prompt, system_prompt="ä½ æ˜¯ä¸€ä½å®è§‚ç»æµåˆ†æä¸“å®¶ï¼Œè¯·åŸºäºæä¾›çš„çœŸå®æ•°æ®è¿›è¡Œåˆ†æ")
    
    def analyze_policy_impact(self, context):
        """åˆ†ææ”¿ç­–å½±å“"""
        print("ğŸ“œ åˆ†ææ”¿ç­–å½±å“")
        country = self.p.get_config().get("country", "ä¸­å›½")
        industry_name = self.p.get_config().get("industry", "")
        
        # æ•´åˆå®è§‚æ”¿ç­–æ•°æ®
        macro_data = self._gather_macro_data(context, country)
        
        # å¦‚æœæ˜¯è¡Œä¸šç ”æŠ¥ï¼Œè¿˜è¦æ•´åˆè¡Œä¸šæ”¿ç­–æ•°æ®
        industry_data = {}
        if industry_name and self.current_report_type == ReportType.INDUSTRY:
            industry_data = self._gather_industry_data(context, industry_name)
        
        if not macro_data and not industry_data:
            return "ç¼ºå°‘æ”¿ç­–æ•°æ®ï¼Œè¯·å…ˆæ‰§è¡Œæ•°æ®æ”¶é›†æ­¥éª¤"
        
        # æ„å»ºåŒ…å«å®é™…æ•°æ®çš„åˆ†æprompt
        analysis_prompt = f"""
        åŸºäºä»¥ä¸‹æ”¶é›†åˆ°çš„æ”¿ç­–æ•°æ®ï¼Œè¯·åˆ†æå½“å‰æ”¿ç­–ç¯å¢ƒå¯¹ç»æµå’Œç›¸å…³è¡Œä¸šçš„å½±å“ï¼š

        === å®è§‚æ”¿ç­–æ•°æ® ===
        {macro_data.get('policy', 'æš‚æ— å®è§‚æ”¿ç­–æ•°æ®')}

        === GDPç›¸å…³æ”¿ç­–å½±å“ ===
        {macro_data.get('gdp', 'æš‚æ— GDPæ•°æ®')}

        === è´§å¸æ”¿ç­–æ•°æ® ===
        {macro_data.get('interest_rate', 'æš‚æ— åˆ©ç‡æ”¿ç­–æ•°æ®')}
        {macro_data.get('federal_reserve', 'æš‚æ— ç¾è”å‚¨æ”¿ç­–æ•°æ®')}
        """
        
        # å¦‚æœæœ‰è¡Œä¸šæ•°æ®ï¼Œæ·»åŠ è¡Œä¸šæ”¿ç­–éƒ¨åˆ†
        if industry_data:
            analysis_prompt += f"""
        === è¡Œä¸šæ”¿ç­–æ•°æ® ===
        {industry_data.get('policy_impact', 'æš‚æ— è¡Œä¸šæ”¿ç­–æ•°æ®')}
        """
        
        analysis_prompt += """
        è¯·åŸºäºä»¥ä¸ŠçœŸå®æ•°æ®åˆ†æï¼š
        1. è´¢æ”¿æ”¿ç­–çš„åˆºæ¿€æ•ˆæœå’ŒæŒç»­æ€§ï¼ˆå¼•ç”¨å…·ä½“æ”¿ç­–æ•°æ®ï¼‰
        2. è´§å¸æ”¿ç­–çš„ä¼ å¯¼æœºåˆ¶å’Œæ•ˆæœï¼ˆåŸºäºåˆ©ç‡å’ŒæµåŠ¨æ€§æ•°æ®ï¼‰
        3. è¡Œä¸šæ”¿ç­–å¯¹ç‰¹å®šé¢†åŸŸçš„æ‰¶æŒåŠ›åº¦ï¼ˆå¦‚æœ‰è¡Œä¸šæ•°æ®ï¼‰
        4. æ”¿ç­–åè°ƒæ€§å’Œæœªæ¥æ”¿ç­–é¢„æœŸï¼ˆç»¼åˆå„é¡¹æ”¿ç­–æ•°æ®ï¼‰
        
        è¯·ç¡®ä¿åˆ†æç»“è®ºæœ‰æ•°æ®æ”¯æ’‘ï¼Œé¿å…ç©ºæ³›æè¿°ã€‚
        """
        
        return self.llm.call(analysis_prompt, system_prompt="ä½ æ˜¯ä¸€ä½æ”¿ç­–åˆ†æä¸“å®¶ï¼Œè¯·åŸºäºæä¾›çš„çœŸå®æ•°æ®è¿›è¡Œåˆ†æ")

    #### æŠ¥å‘Šç”Ÿæˆå·¥å…·æ‰©å±• ####
    def generate_industry_report(self, context):
        """åˆ†æ®µç”Ÿæˆè¡Œä¸šç ”æŠ¥"""
        print("ğŸ“ åˆ†æ®µç”Ÿæˆè¡Œä¸šç ”æŠ¥")
        industry_name = self.p.get_config().get("industry", "äººå·¥æ™ºèƒ½")

        # æå–åˆ†æç»“æœå’Œæ•°æ®
        industry_analysis = context.get("analyze_industry_structure", "")
        trends_analysis = context.get("analyze_industry_trends", "")
        collected_data = self._gather_industry_data(context, industry_name)

        def call_llm_section(title, instruction, content):
            prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è¡Œä¸šç ”ç©¶åˆ†æå¸ˆï¼Œè¯·æ ¹æ®ä»¥ä¸‹å†…å®¹æ’°å†™ã€Š{industry_name}ã€‹è¡Œä¸šç ”æŠ¥ä¸­çš„ã€{title}ã€‘éƒ¨åˆ†ã€‚

ã€å†™ä½œè¦æ±‚ã€‘
- {instruction}
- ä½¿ç”¨ä¸“ä¸šæœ¯è¯­ï¼Œé€»è¾‘ä¸¥å¯†ï¼Œè¯­è¨€ç²¾ç‚¼ï¼Œç¯‡å¹…æ§åˆ¶åœ¨500-800å­—ã€‚

ã€åŸå§‹åˆ†ææ•°æ®ã€‘
{content}
"""
            return self.llm.call(prompt, system_prompt="ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è¡Œä¸šç ”ç©¶åˆ†æå¸ˆï¼Œæ“…é•¿æ’°å†™æ·±åº¦è¡Œä¸šç ”æŠ¥ã€‚")

        # æ¯æ®µç”Ÿæˆå†…å®¹
        sections = []

        sections.append(("è¡Œä¸šæ¦‚å†µ", call_llm_section(
            "è¡Œä¸šæ¦‚å†µ", "ä»‹ç»è¡Œä¸šæ•´ä½“æƒ…å†µï¼ŒåŒ…æ‹¬å‘å±•èƒŒæ™¯ã€ä¸»è¦åº”ç”¨é¢†åŸŸä¸ç°çŠ¶",
            collected_data.get('overview', 'æš‚æ— æ•°æ®'))))

        sections.append(("äº§ä¸šé“¾åˆ†æ", call_llm_section(
            "äº§ä¸šé“¾åˆ†æ", "ä»ä¸Šæ¸¸ã€ä¸­æ¸¸ã€ä¸‹æ¸¸ä¸‰ä¸ªç¯èŠ‚åˆ†æè¡Œä¸šçš„äº§ä¸šé“¾ç»“æ„",
            industry_analysis)))

        sections.append(("å¸‚åœºè§„æ¨¡ä¸ç«äº‰æ ¼å±€", call_llm_section(
            "å¸‚åœºè§„æ¨¡ä¸ç«äº‰æ ¼å±€", "è¯´æ˜å¸‚åœºè§„æ¨¡ã€ä¸»è¦ä¼ä¸šã€ç«äº‰æ€åŠ¿",
            collected_data.get('market_scale', '') + "\n" + collected_data.get('leading_companies', ''))))

        sections.append(("æŠ€æœ¯å‘å±•è¶‹åŠ¿", call_llm_section(
            "æŠ€æœ¯å‘å±•è¶‹åŠ¿", "æç‚¼è¡Œä¸šä¸­çš„æ ¸å¿ƒæŠ€æœ¯æ¼”è¿›è·¯å¾„å’Œåˆ›æ–°æ–¹å‘",
            trends_analysis)))

        sections.append(("æ”¿ç­–ç¯å¢ƒåˆ†æ", call_llm_section(
            "æ”¿ç­–ç¯å¢ƒåˆ†æ", "æ¢³ç†æ”¿ç­–æ³•è§„ã€è¡¥è´´ç­‰å¯¹è¡Œä¸šçš„å½±å“",
            collected_data.get('policy', 'æš‚æ— æ•°æ®'))))

        sections.append(("æŠ•èµ„æœºä¼šä¸é£é™©", call_llm_section(
            "æŠ•èµ„æœºä¼šä¸é£é™©", "ç»¼åˆä»¥ä¸Šå†…å®¹ï¼Œæå‡ºæŠ•èµ„å»ºè®®å¹¶æŒ‡å‡ºæ½œåœ¨é£é™©",
            "\n".join([s[1] for s in sections[:5]]))))  # å‰5æ®µä¸ºåŸºç¡€

        # ç»„è£… Markdown æ ¼å¼ç ”æŠ¥
        report_content = f"# {industry_name}è¡Œä¸šç ”ç©¶æŠ¥å‘Š\n\n"
        for title, content in sections:
            report_content += f"## {title}\n\n{content.strip()}\n\n"

        # ä¿å­˜æ–‡ä»¶
        output_file = f"è¡Œä¸šç ”æŠ¥_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        save_markdown(report_content, output_file)

        # ğŸ¯ ä¿å­˜æŠ¥å‘Šè·¯å¾„åˆ°ç±»å±æ€§
        self._update_report_path("industry_report", output_file)

        return {"industry_report_file": output_file, "content": report_content}
    

    def generate_macro_report(self, context):
        """åˆ†æ®µç”Ÿæˆå®è§‚ç»æµç ”æŠ¥"""
        print("ğŸ“Š ç”Ÿæˆå®è§‚ç»æµç ”æŠ¥ï¼ˆåˆ†æ®µï¼‰")
        country = self.p.get_config().get("country", "ä¸­å›½")

        macro_trends = context.get("analyze_macro_trends", "")
        policy_impact = context.get("analyze_policy_impact", "")
        collected_data = self._gather_macro_data(context, country)

        # é™åˆ¶è¾“å…¥æ•°æ®é•¿åº¦
        def truncate(txt, maxlen=500):
            return txt[:maxlen] + "..." if len(txt) > maxlen else txt

        # åˆ†æ®µæ¨¡æ¿
        sections = [
            {
                "title": "1. å®è§‚ç»æµæ¦‚å†µ",
                "instruction": f"""ä½ æ˜¯ä¸€ä½èµ„æ·±å®è§‚åˆ†æå¸ˆï¼Œè¯·æ ¹æ®ä»¥ä¸‹ä¸­å›½å®è§‚æ•°æ®åˆ†ææ•´ä½“ç»æµçŠ¶å†µï¼š
    - GDP: {truncate(collected_data.get('gdp', 'æš‚æ— '))}
    - CPI: {truncate(collected_data.get('cpi', 'æš‚æ— '))}
    è¯·è¾“å‡ºä¸€æ®µ500å­—å·¦å³çš„åˆ†æã€‚"""
            },
            {
                "title": "2. è´§å¸æ”¿ç­–åˆ†æ",
                "instruction": f"""è¯·åˆ†æä¸­å›½å½“å‰è´§å¸æ”¿ç­–è¶‹åŠ¿ï¼ŒåŸºäºä»¥ä¸‹ä¿¡æ¯ï¼š
    - åˆ©ç‡æƒ…å†µ: {truncate(collected_data.get('interest_rate', 'æš‚æ— '))}
    - å®è§‚è¶‹åŠ¿: {truncate(macro_trends)}
    è¦æ±‚ï¼šæ¢³ç†è´§å¸æ”¿ç­–å˜åŒ–èƒŒæ™¯ï¼Œç»“åˆåˆ©ç‡æˆ–æµåŠ¨æ€§è¿›è¡Œåˆ†æã€‚"""
            },
            {
                "title": "3. è´¢æ”¿æ”¿ç­–åˆ†æ",
                "instruction": f"""è¯·åˆ†æå½“å‰è´¢æ”¿æ”¿ç­–å¯¹å®è§‚ç»æµçš„å½±å“ï¼Œæ•°æ®å‚è€ƒï¼š
    - æ”¿ç­–æ‘˜è¦: {truncate(policy_impact)}
    - æ”¿ç­–æ–‡ä»¶åŸæ–‡: {truncate(collected_data.get('policy', 'æš‚æ— '))}"""
            },
            {
                "title": "4. å›½é™…ç¯å¢ƒå½±å“",
                "instruction": f"""è¯·åˆ†æå›½é™…å®è§‚ç¯å¢ƒå¯¹ä¸­å›½çš„å½±å“ï¼ŒåŒ…æ‹¬æ±‡ç‡ã€ç¾è”å‚¨åŠ æ¯ç­‰å†…å®¹ã€‚
    - æ±‡ç‡èµ°åŠ¿: {truncate(collected_data.get('exchange_rate', 'æš‚æ— '))}"""
            },
            {
                "title": "5. è¡Œä¸šå½±å“åˆ†æ",
                "instruction": f"""ç»“åˆä¸Šé¢çš„å®è§‚åˆ†æï¼Œåˆ¤æ–­ä¸­å›½å“ªäº›è¡Œä¸šå—ç›Š/å—æŒ«ï¼Œå¹¶è¯´æ˜åŸå› ã€‚"""
            },
            {
                "title": "6. æŠ•èµ„ç­–ç•¥å»ºè®®",
                "instruction": f"""åŸºäºä¸Šè¿°å®è§‚åˆ¤æ–­ï¼Œæå‡ºå…·ä½“çš„æŠ•èµ„å»ºè®®ï¼Œæ ‡æ˜æ¨èèµ„äº§ç±»åˆ«åŠåŸå› ã€‚"""
            }
        ]

        def safe_llm_call(prompt, sys_prompt=None, retries=3):
            for i in range(retries):
                try:
                    return self.llm.call(prompt, system_prompt=sys_prompt)
                except Exception as e:
                    print(f"âš ï¸ LLMè°ƒç”¨å¤±è´¥ï¼ˆç¬¬{i+1}æ¬¡ï¼‰: {e}")
                    time.sleep(1)
            return "ã€ç”Ÿæˆå¤±è´¥ã€‘è¿æ¥é”™è¯¯"

        report_parts = []
        for i, sec in enumerate(sections):
            print(f"âœï¸ æ­£åœ¨ç”Ÿæˆ {sec['title']}")
            content = safe_llm_call(
                sec["instruction"],
                sys_prompt="ä½ æ˜¯ä¸€ä½èµ„æ·±å®è§‚ç»æµç ”ç©¶å‘˜ï¼Œè¯·è¾“å‡ºç»“æ„æ¸…æ™°ã€ä¸“ä¸šã€ç®€æ´çš„åˆ†æå†…å®¹ã€‚"
            )
            section_text = f"## {sec['title']}\n\n{content.strip()}\n"
            report_parts.append(section_text)

        # æ‹¼æ¥å®Œæ•´å†…å®¹
        full_report = "# å®è§‚ç»æµç ”æŠ¥\n\n" + "\n".join(report_parts)

        # ä¿å­˜
        output_file = f"{country}å®è§‚ç»æµç ”æŠ¥_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        save_markdown(full_report, output_file)

        # ğŸ¯ ä¿å­˜æŠ¥å‘Šè·¯å¾„åˆ°ç±»å±æ€§
        self._update_report_path("macro_report", output_file)

        print(f"âœ… æŠ¥å‘Šç”Ÿæˆå®Œæ¯•ï¼Œä¿å­˜è‡³ {output_file}")
        return {
            "macro_report_file": output_file,
            "content": full_report
        }

    #### ç ”æŠ¥è¯„ä»·å·¥å…· ####
    def load_report_content(self, context):
        """åŠ è½½ç ”æŠ¥å†…å®¹è¿›è¡Œè¯„ä»·"""
        # 1.è·å–æŠ¥å‘Šå†…å®¹
        base_path = Path(".")
        files = []
        if self.current_report_type == ReportType.COMPANY:
            files = base_path.glob("æ·±åº¦è´¢åŠ¡ç ”æŠ¥åˆ†æ*.md")
        elif self.current_report_type == ReportType.INDUSTRY:
            files = base_path.glob("è¡Œä¸šç ”æŠ¥*.md")
        elif self.current_report_type == ReportType.MACRO:
            files = base_path.glob("ä¸­å›½å®è§‚ç»æµç ”æŠ¥*.md")
        else:
            print(f"æœªçŸ¥çš„æŠ¥å‘Šç±»å‹: {self.current_report_type}")
            return

        content = ""
        for file_path in files:
            content = file_path.read_text(encoding="utf-8")
            print(f"===== {file_path} =====")
            print(content[:200])

        # 2.ä¿å­˜åˆ°context
        if content:
            self.m.context_set("report_content", content)
        else:
            print("æœªæ‰¾åˆ°åŒ¹é…çš„æŠ¥å‘Šæ–‡ä»¶")

    def identify_report_type_for_evaluation(self, context):
        """è¯†åˆ«ç ”æŠ¥ç±»å‹ä»¥é€‰æ‹©åˆé€‚çš„è¯„ä»·æ ‡å‡†"""
        report_content = self.m.context_get("report_content")
        if not report_content:
            return "è¯·å…ˆåŠ è½½ç ”æŠ¥å†…å®¹"
        
        # ä½¿ç”¨ç°æœ‰çš„æŠ¥å‘Šç±»å‹é…ç½®è¯†åˆ«
        report_type = self.report_config.identify_report_type(report_content)
        
        self.m.context_set("evaluation_report_type", report_type)
        self.m.context_set("report_type_identified", True)
        
        type_name = self.report_config.get_config(report_type)['name']
        return f"è¯†åˆ«ç ”æŠ¥ç±»å‹ä¸º: {type_name}"
    
    def evaluate_content_completeness(self, context):
        """è¯„ä»·å†…å®¹å®Œæ•´æ€§"""
        return self._evaluate_report_dimension(context, "content_completeness", "å†…å®¹å®Œæ•´æ€§")
    
    def evaluate_data_accuracy(self, context):
        """è¯„ä»·æ•°æ®å‡†ç¡®æ€§"""
        return self._evaluate_report_dimension(context, "data_accuracy", "æ•°æ®å‡†ç¡®æ€§")
    
    def evaluate_analysis_depth(self, context):
        """è¯„ä»·åˆ†ææ·±åº¦"""
        return self._evaluate_report_dimension(context, "analysis_depth", "åˆ†ææ·±åº¦")
    
    def evaluate_logical_coherence(self, context):
        """è¯„ä»·é€»è¾‘ä¸€è‡´æ€§"""
        return self._evaluate_report_dimension(context, "logical_coherence", "é€»è¾‘ä¸€è‡´æ€§")
    
    def evaluate_professional_quality(self, context):
        """è¯„ä»·ä¸“ä¸šæ€§"""
        return self._evaluate_report_dimension(context, "professional_quality", "ä¸“ä¸šæ€§")
    
    def evaluate_market_insight(self, context):
        """è¯„ä»·å¸‚åœºæ´å¯ŸåŠ›ï¼ˆè¡Œä¸šç ”æŠ¥ä¸“ç”¨ï¼‰"""
        return self._evaluate_report_dimension(context, "market_insight", "å¸‚åœºæ´å¯ŸåŠ›")
    
    def evaluate_macroeconomic_insight(self, context):
        """è¯„ä»·å®è§‚æ´å¯ŸåŠ›ï¼ˆå®è§‚ç ”æŠ¥ä¸“ç”¨ï¼‰"""
        return self._evaluate_report_dimension(context, "macroeconomic_insight", "å®è§‚æ´å¯ŸåŠ›")
    
    def calculate_overall_evaluation_score(self, context):
        """è®¡ç®—ç»¼åˆè¯„åˆ†"""
        report_type = self.m.context_get("evaluation_report_type")
        if not report_type:
            return {"error": "è¯·å…ˆè¯†åˆ«ç ”æŠ¥ç±»å‹"}
        
        # è¯„ä»·æ ‡å‡†æƒé‡é…ç½®
        criteria_weights = self._get_evaluation_criteria(report_type)
        
        overall_score = 0.0
        detailed_scores = {}
        
        # æ±‡æ€»å„ç»´åº¦è¯„åˆ†
        for dimension_name, weight in criteria_weights.items():
            score_data = self.m.context_get(f"{dimension_name}_evaluation")
            if score_data and isinstance(score_data, dict):
                dimension_score = score_data.get("score", 0)
                weighted_score = dimension_score * weight
                overall_score += weighted_score
                
                detailed_scores[dimension_name] = {
                    "score": dimension_score,
                    "weight": weight,
                    "weighted_score": weighted_score,
                    "feedback": score_data.get("feedback", "")
                }
        
        # è¯„åˆ†ç­‰çº§
        grade = self._get_evaluation_grade(overall_score)
        
        final_result = {
            "overall_score": round(overall_score, 2),
            "grade": grade,
            "detailed_scores": detailed_scores,
            "evaluation_time": datetime.now().isoformat(),
            "report_type": self.report_config.get_config(report_type)["name"]
        }
        
        self.m.context_set("final_evaluation", final_result)
        return final_result
    
    def generate_evaluation_report(self, context):
        """ç”Ÿæˆè¯„ä»·æŠ¥å‘Š"""
        final_evaluation = self.m.context_get("final_evaluation")
        if not final_evaluation:
            return "è¯·å…ˆå®Œæˆç»¼åˆè¯„åˆ†è®¡ç®—"
        
        report_template = f"""
# ç ”æŠ¥è´¨é‡è¯„ä»·æŠ¥å‘Š

## åŸºæœ¬ä¿¡æ¯
- **ç ”æŠ¥ç±»å‹**: {final_evaluation['report_type']}
- **è¯„ä»·æ—¶é—´**: {final_evaluation['evaluation_time']}
- **ç»¼åˆè¯„åˆ†**: {final_evaluation['overall_score']}/100
- **è¯„ä»·ç­‰çº§**: {final_evaluation['grade']}

## è¯¦ç»†è¯„åˆ†

{self._format_detailed_scores(final_evaluation['detailed_scores'])}

## è¯„ä»·æ€»ç»“

{self._generate_evaluation_summary(final_evaluation)}

## è¯„åˆ†è¯´æ˜
- Açº§ (90-100åˆ†): ä¼˜ç§€ï¼Œè¾¾åˆ°è¡Œä¸šé¢†å…ˆæ°´å¹³
- Bçº§ (80-89åˆ†): è‰¯å¥½ï¼Œç¬¦åˆä¸“ä¸šæ ‡å‡†  
- Cçº§ (70-79åˆ†): åˆæ ¼ï¼ŒåŸºæœ¬æ»¡è¶³è¦æ±‚
- Dçº§ (60-69åˆ†): éœ€è¦æ”¹è¿›
- Fçº§ (0-59åˆ†): ä¸åˆæ ¼ï¼Œéœ€è¦é‡æ–°æ’°å†™
        """
        
        self.m.context_set("evaluation_report", report_template.strip())
        return "è¯„ä»·æŠ¥å‘Šç”Ÿæˆå®Œæˆ"
    
    def save_evaluation_result(self, context):
        """ä¿å­˜è¯„ä»·ç»“æœ"""
        evaluation_report = self.m.context_get("evaluation_report")
        final_evaluation = self.m.context_get("final_evaluation")
        
        if not evaluation_report or not final_evaluation:
            return "è¯·å…ˆç”Ÿæˆè¯„ä»·æŠ¥å‘Š"
        
        # ç¡®å®šä¿å­˜è·¯å¾„
        report_path = "./"
        if report_path:
            base_dir = os.path.dirname(report_path)
            base_name = os.path.splitext(os.path.basename(report_path))[0]
        else:
            base_dir = os.path.join(self.m.data_dir, "evaluation")
            base_name = f"evaluation_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
        os.makedirs(base_dir, exist_ok=True)
        
        # ä¿å­˜è¯„ä»·æŠ¥å‘Š
        report_file = os.path.join(base_dir, f"{base_name}_evaluation.md")
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(evaluation_report)
        
        # ä¿å­˜è¯„åˆ†æ•°æ®
        json_file = os.path.join(base_dir, f"{base_name}_scores.json") 
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(final_evaluation, f, ensure_ascii=False, indent=2)
        
        return f"è¯„ä»·ç»“æœå·²ä¿å­˜:\n- æŠ¥å‘Š: {report_file}\n- æ•°æ®: {json_file}"
    
    def _evaluate_report_dimension(self, context, dimension, dimension_name):
        """é€šç”¨ç»´åº¦è¯„ä»·æ–¹æ³•"""
        report_content = self.m.context_get("report_content")
        report_type = self.m.context_get("evaluation_report_type")
        
        if not report_content or not report_type:
            return {"error": "è¯·å…ˆåŠ è½½ç ”æŠ¥å†…å®¹å¹¶è¯†åˆ«ç±»å‹"}
        
        # è·å–è¯„ä»·æ ‡å‡†
        criteria = self._get_dimension_criteria(report_type, dimension)
        if not criteria:
            return {"error": f"è¯¥ç ”æŠ¥ç±»å‹ä¸æ”¯æŒ{dimension_name}è¯„ä»·"}
        
        # æ„å»ºè¯„ä»·prompt
        evaluation_prompt = self._build_evaluation_prompt(
            report_content, dimension_name, criteria, report_type
        )
        
        try:
            # è°ƒç”¨LLMè¿›è¡Œè¯„ä»·
            response = self.llm.call(
                evaluation_prompt,
                system_prompt="ä½ æ˜¯ä¸“ä¸šçš„é‡‘èç ”æŠ¥è¯„ä»·ä¸“å®¶ï¼Œè¯·å®¢è§‚å…¬æ­£åœ°è¿›è¡Œè¯„ä»·ã€‚",
                temperature=0.3
            )
            
            # è§£æè¯„åˆ†ç»“æœ
            result = self._parse_evaluation_result(response, dimension_name)
            self.m.context_set(f"{dimension}_evaluation", result)
            
            return result
            
        except Exception as e:
            return {"error": f"{dimension_name}è¯„ä»·å¤±è´¥: {str(e)}"}
    
    def _get_evaluation_criteria(self, report_type):
        """è·å–è¯„ä»·æ ‡å‡†æƒé‡"""
        criteria_mapping = {
            ReportType.COMPANY: {
                "content_completeness": 0.25,
                "data_accuracy": 0.20,
                "analysis_depth": 0.25,
                "logical_coherence": 0.15,
                "professional_quality": 0.15
            },
            ReportType.INDUSTRY: {
                "content_completeness": 0.25,
                "market_insight": 0.25,
                "data_accuracy": 0.20,
                "analysis_depth": 0.15,
                "professional_quality": 0.15
            },
            ReportType.MACRO: {
                "macroeconomic_insight": 0.30,
                "data_accuracy": 0.20,
                "analysis_depth": 0.20,
                "logical_coherence": 0.15,
                "professional_quality": 0.15
            }
        }
        return criteria_mapping.get(report_type, criteria_mapping[ReportType.COMPANY])
    
    def _get_dimension_criteria(self, report_type, dimension):
        """è·å–å…·ä½“ç»´åº¦çš„è¯„ä»·ç»†åˆ™"""
        criteria_details = {
            ReportType.COMPANY: {
                "content_completeness": ["å…¬å¸æ¦‚å†µæè¿°æ˜¯å¦å…¨é¢", "è´¢åŠ¡åˆ†ææ˜¯å¦æ·±å…¥", "ç«äº‰å¯¹æ‰‹åˆ†ææ˜¯å¦åˆ°ä½", "æŠ•èµ„å»ºè®®æ˜¯å¦æ˜ç¡®", "é£é™©æç¤ºæ˜¯å¦å……åˆ†"],
                "data_accuracy": ["è´¢åŠ¡æ•°æ®å¼•ç”¨æ˜¯å¦å‡†ç¡®", "æ•°æ®è®¡ç®—æ˜¯å¦æ­£ç¡®", "æ•°æ®æ¥æºæ˜¯å¦å¯é ", "æ•°æ®æ—¶æ•ˆæ€§æ˜¯å¦åˆé€‚"],
                "analysis_depth": ["è´¢åŠ¡åˆ†ææ˜¯å¦æ·±å…¥é€å½»", "ä¸šåŠ¡æ¨¡å¼åˆ†ææ˜¯å¦æ¸…æ™°", "è¡Œä¸šåœ°ä½åˆ†ææ˜¯å¦å‡†ç¡®", "ä¼°å€¼åˆ†ææ˜¯å¦åˆç†"],
                "logical_coherence": ["è®ºè¯é€»è¾‘æ˜¯å¦æ¸…æ™°", "ç»“è®ºä¸åˆ†ææ˜¯å¦ä¸€è‡´", "ç« èŠ‚é—´é€»è¾‘æ˜¯å¦è¿è´¯"],
                "professional_quality": ["ä¸“ä¸šæœ¯è¯­ä½¿ç”¨æ˜¯å¦å‡†ç¡®", "åˆ†ææ–¹æ³•æ˜¯å¦ç§‘å­¦", "è¡¨è¾¾æ˜¯å¦ä¸“ä¸šè§„èŒƒ"]
            },
            ReportType.INDUSTRY: {
                "content_completeness": ["è¡Œä¸šæ¦‚å†µæ˜¯å¦å…¨é¢", "äº§ä¸šé“¾åˆ†ææ˜¯å¦å®Œæ•´", "å¸‚åœºè§„æ¨¡åˆ†ææ˜¯å¦å‡†ç¡®", "æŠ€æœ¯è¶‹åŠ¿åˆ†ææ˜¯å¦åˆ°ä½", "æ”¿ç­–åˆ†ææ˜¯å¦å……åˆ†"],
                "market_insight": ["è¡Œä¸šå‘å±•è¶‹åŠ¿åˆ¤æ–­æ˜¯å¦å‡†ç¡®", "ç«äº‰æ ¼å±€åˆ†ææ˜¯å¦æ·±å…¥", "å¸‚åœºæœºä¼šè¯†åˆ«æ˜¯å¦ç²¾å‡†", "è¡Œä¸šç—›ç‚¹åˆ†ææ˜¯å¦åˆ°ä½"],
                "data_accuracy": ["æ•°æ®è¦†ç›–èŒƒå›´æ˜¯å¦å¹¿æ³›", "æ•°æ®ç»´åº¦æ˜¯å¦å…¨é¢", "å†å²æ•°æ®æ˜¯å¦å……åˆ†", "é¢„æµ‹æ•°æ®æ˜¯å¦åˆç†"],
                "analysis_depth": ["åˆ†ææ¡†æ¶æ˜¯å¦ç§‘å­¦", "åˆ†ææ–¹æ³•æ˜¯å¦åˆé€‚", "åˆ†æå±‚æ¬¡æ˜¯å¦æ¸…æ™°"],
                "professional_quality": ["æŠ•èµ„å»ºè®®æ˜¯å¦å…·ä½“", "é£é™©æç¤ºæ˜¯å¦å®ç”¨", "ç»“è®ºæ˜¯å¦æœ‰æŒ‡å¯¼æ„ä¹‰"]
            },
            ReportType.MACRO: {
                "macroeconomic_insight": ["å®è§‚è¶‹åŠ¿åˆ¤æ–­æ˜¯å¦å‡†ç¡®", "æ”¿ç­–è§£è¯»æ˜¯å¦æ·±å…¥", "å›½é™…å½±å“åˆ†ææ˜¯å¦åˆ°ä½", "ç»æµå‘¨æœŸåˆ¤æ–­æ˜¯å¦åˆç†"],
                "data_accuracy": ["æ•°æ®æ¥æºæ˜¯å¦æƒå¨", "æ•°æ®å¤„ç†æ˜¯å¦ç§‘å­¦", "æ•°æ®è§£è¯»æ˜¯å¦å‡†ç¡®", "é¢„æµ‹æ•°æ®æ˜¯å¦åˆç†"],
                "analysis_depth": ["è´§å¸æ”¿ç­–åˆ†ææ˜¯å¦æ·±å…¥", "è´¢æ”¿æ”¿ç­–å½±å“æ˜¯å¦å‡†ç¡®", "æ”¿ç­–ä¼ å¯¼æœºåˆ¶æ˜¯å¦æ¸…æ™°", "æ”¿ç­–æ•ˆæœé¢„åˆ¤æ˜¯å¦åˆç†"],
                "logical_coherence": ["è¶‹åŠ¿é¢„æµ‹æ˜¯å¦åˆç†", "é£é™©é¢„è­¦æ˜¯å¦åŠæ—¶", "æœºä¼šè¯†åˆ«æ˜¯å¦å‡†ç¡®", "æ—¶é—´çª—å£åˆ¤æ–­æ˜¯å¦åˆé€‚"],
                "professional_quality": ["æŠ•èµ„ç­–ç•¥æ˜¯å¦å…·ä½“", "èµ„äº§é…ç½®å»ºè®®æ˜¯å¦åˆç†", "æ—¶æœºæŠŠæ¡æ˜¯å¦å‡†ç¡®", "é£é™©æ§åˆ¶å»ºè®®æ˜¯å¦æœ‰æ•ˆ"]
            }
        }
        
        type_criteria = criteria_details.get(report_type, criteria_details[ReportType.COMPANY])
        return type_criteria.get(dimension, [])
    
    def _build_evaluation_prompt(self, report_content, dimension_name, criteria, report_type):
        """æ„å»ºè¯„ä»·prompt"""
        type_name = self.report_config.get_config(report_type)['name']
        
        prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„é‡‘èç ”æŠ¥è¯„ä»·ä¸“å®¶ï¼Œè¯·å¯¹ä»¥ä¸‹{type_name}åœ¨"{dimension_name}"ç»´åº¦è¿›è¡Œå®¢è§‚è¯„ä»·ã€‚

## è¯„ä»·æ ‡å‡†
{dimension_name}ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹æ–¹é¢ï¼š
"""
        
        for i, criterion in enumerate(criteria, 1):
            prompt += f"{i}. {criterion}\n"
        
        # æˆªå–æŠ¥å‘Šå†…å®¹ï¼ˆé¿å…è¿‡é•¿ï¼‰
        content_preview = report_content[:4000] + "..." if len(report_content) > 4000 else report_content
        
        prompt += f"""

## ç ”æŠ¥å†…å®¹
{content_preview}

## è¯„ä»·è¦æ±‚
è¯·ä»”ç»†é˜…è¯»ç ”æŠ¥å†…å®¹ï¼Œæ ¹æ®ä¸Šè¿°è¯„ä»·æ ‡å‡†è¿›è¡Œè¯„ä»·ï¼š
1. é€é¡¹æ£€æŸ¥æ˜¯å¦æ»¡è¶³è¯„ä»·æ ‡å‡†
2. ç»™å‡º0-100åˆ†çš„è¯„åˆ†ï¼ˆåˆ†æ•°è¶Šé«˜è¡¨ç¤ºè´¨é‡è¶Šå¥½ï¼‰
3. æä¾›å…·ä½“çš„è¯„ä»·åé¦ˆï¼ŒåŒ…æ‹¬ä¼˜ç‚¹å’Œä¸è¶³
4. è¯„ä»·è¦å®¢è§‚å…¬æ­£ï¼Œæœ‰ç†æœ‰æ®

## è¾“å‡ºæ ¼å¼
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼ˆä¸è¦æ·»åŠ å…¶ä»–å†…å®¹ï¼‰ï¼š
{{
    "score": è¯„åˆ†æ•°å­—(0-100çš„æ•´æ•°),
    "feedback": "å…·ä½“çš„è¯„ä»·åé¦ˆï¼ŒåŒ…æ‹¬ä¼˜ç‚¹å’Œä¸è¶³ï¼Œ200-300å­—"
}}
"""
        
        return prompt
    
    def _parse_evaluation_result(self, response, dimension_name):
        """è§£æLLMè¯„ä»·ç»“æœ"""
        try:
            # å°è¯•ä»å“åº”ä¸­æå–JSON
            import re
            json_pattern = r'\{[^{}]*"score"[^{}]*"feedback"[^{}]*\}'
            json_match = re.search(json_pattern, response, re.DOTALL)
            
            if json_match:
                json_str = json_match.group(0)
                result = json.loads(json_str)
                
                # éªŒè¯å¿…è¦å­—æ®µ
                if "score" in result and "feedback" in result:
                    # ç¡®ä¿åˆ†æ•°åœ¨æœ‰æ•ˆèŒƒå›´å†…
                    result["score"] = max(0, min(100, int(result["score"])))
                    return result
            
            # å¦‚æœJSONè§£æå¤±è´¥ï¼Œå°è¯•ç®€å•è§£æ
            score_match = re.search(r'(\d+)', response)
            score = int(score_match.group(1)) if score_match else 70
            
            return {
                "score": max(0, min(100, score)),
                "feedback": f"{dimension_name}è¯„ä»·ï¼š" + response[:300],
            }
            
        except Exception as e:
            return {
                "score": 70,
                "feedback": f"è¯„ä»·è§£æå¤±è´¥: {str(e)}ï¼ŒåŸå§‹å›å¤ï¼š{response[:200]}",
            }
    
    def _get_evaluation_grade(self, score):
        """æ ¹æ®åˆ†æ•°è·å–ç­‰çº§"""
        if score >= 90:
            return "Açº§ (ä¼˜ç§€)"
        elif score >= 80:
            return "Bçº§ (è‰¯å¥½)"
        elif score >= 70:
            return "Cçº§ (åˆæ ¼)"
        elif score >= 60:
            return "Dçº§ (éœ€è¦æ”¹è¿›)"
        else:
            return "Fçº§ (ä¸åˆæ ¼)"
    
    def _format_detailed_scores(self, detailed_scores):
        """æ ¼å¼åŒ–è¯¦ç»†è¯„åˆ†"""
        formatted = ""
        for dimension, scores in detailed_scores.items():
            dimension_name = {
                "content_completeness": "å†…å®¹å®Œæ•´æ€§",
                "data_accuracy": "æ•°æ®å‡†ç¡®æ€§", 
                "analysis_depth": "åˆ†ææ·±åº¦",
                "logical_coherence": "é€»è¾‘ä¸€è‡´æ€§",
                "professional_quality": "ä¸“ä¸šæ€§",
                "market_insight": "å¸‚åœºæ´å¯ŸåŠ›",
                "macroeconomic_insight": "å®è§‚æ´å¯ŸåŠ›"
            }.get(dimension, dimension)
            
            formatted += f"""
### {dimension_name}
- **å¾—åˆ†**: {scores['score']}/100 (æƒé‡: {scores['weight']})
- **åŠ æƒå¾—åˆ†**: {scores['weighted_score']:.2f}
- **åé¦ˆ**: {scores['feedback']}
"""
        return formatted
    
    def _generate_evaluation_summary(self, final_evaluation):
        """ç”Ÿæˆè¯„ä»·æ€»ç»“"""
        detailed_scores = final_evaluation['detailed_scores']
        overall_score = final_evaluation['overall_score']
        
        strengths = []
        improvements = []
        
        for dimension, scores in detailed_scores.items():
            if scores['score'] >= 85:
                strengths.append(f"- {dimension}: è¡¨ç°ä¼˜ç§€")
            elif scores['score'] < 70:
                improvements.append(f"- {dimension}: éœ€è¦æ”¹è¿›")
        
        strengths_text = "\n".join(strengths) if strengths else "- å„ç»´åº¦è¡¨ç°å‡è¡¡"
        improvements_text = "\n".join(improvements) if improvements else "- æ•´ä½“è´¨é‡è‰¯å¥½ï¼Œç»§ç»­ä¿æŒ"
        
        summary = f"""
**ä¼˜åŠ¿åˆ†æ:**
{strengths_text}

**æ”¹è¿›å»ºè®®:**
{improvements_text}

**æ€»ä½“è¯„ä»·:**
è¯¥ç ”æŠ¥ç»¼åˆè¯„åˆ†ä¸º{overall_score}åˆ†ï¼Œ{final_evaluation['grade']}ã€‚
"""
        if overall_score >= 80:
            summary += "æ•´ä½“è´¨é‡è¾ƒå¥½ï¼Œç¬¦åˆä¸“ä¸šæ ‡å‡†ã€‚"
        elif overall_score >= 70:
            summary += "åŸºæœ¬æ»¡è¶³è¦æ±‚ï¼Œä½†ä»æœ‰æå‡ç©ºé—´ã€‚"
        else:
            summary += "è´¨é‡æœ‰å¾…æé«˜ï¼Œå»ºè®®é‡ç‚¹æ”¹è¿›è–„å¼±ç¯èŠ‚ã€‚"
            
        return summary
